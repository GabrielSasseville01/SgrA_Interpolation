{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_trainer.py --niters 50 --batch-size 60 --dataset randomwalk --norm --shuffle --sample-tp 0.1 --mse-weight 1.0 --imab-dim 64 --cab-dim 256 --decoder-dim 128 --nlayers 1 --sample-type random --num-ref-points 128 --experiment-id 8938992\n",
      "(50000, 200, 9) (25000, 200, 9) (25000, 200, 9)\n",
      "/home/gsasseville/.local/share/virtualenvs/Tripletformer-nUF7tw2u/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "checkpoint_trainer.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n",
      "Resuming training from checkpoint at Epoch 6\n",
      "Experiment ID 8938992\n",
      "Epoch 6 completed\n",
      "Training loss: 2.5701\n",
      "Validation loss: 2.4873\n",
      "Epoch 7 completed\n",
      "Training loss: 2.4317\n",
      "Validation loss: 2.3652\n",
      "Epoch 8 completed\n",
      "Training loss: 2.3397\n",
      "Validation loss: 2.3439\n",
      "Epoch 9 completed\n",
      "Training loss: 2.2855\n",
      "Validation loss: 2.2312\n",
      "Epoch 10 completed\n",
      "Training loss: 2.2327\n",
      "Validation loss: 2.2065\n",
      "Epoch 11 completed\n",
      "Training loss: 2.2001\n",
      "Validation loss: 2.2255\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"checkpoint_trainer.py\", line 95, in <module>\n",
      "    loss_info = net.compute_unsupervised_loss(\n",
      "  File \"/home/gsasseville/Files/UDEM/Maitrise/SgrA/SgrA_Interpolation/Tripletformer/tripletformer.py\", line 163, in compute_unsupervised_loss\n",
      "    loglik = self.compute_loglik(mask, px, self.norm)\n",
      "  File \"/home/gsasseville/Files/UDEM/Maitrise/SgrA/SgrA_Interpolation/Tripletformer/tripletformer.py\", line 73, in compute_loglik\n",
      "    log_p = utils.log_normal_pdf(\n",
      "  File \"/home/gsasseville/Files/UDEM/Maitrise/SgrA/SgrA_Interpolation/Tripletformer/utils.py\", line 16, in log_normal_pdf\n",
      "    const = torch.from_numpy(np.array([2.0 * np.pi])).float().to(x.device)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python checkpoint_trainer.py --niters 50 --batch-size 60 --dataset randomwalk --norm --shuffle --sample-tp 0.1 --mse-weight 1.0 --imab-dim 64 --cab-dim 256 --decoder-dim 128 --nlayers 1 --sample-type random --num-ref-points 128 --experiment-id 8938992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_prediction.py --batch-size 60 --dataset randomwalk --norm --shuffle --sample-tp 0.1 --mse-weight 1.0 --imab-dim 64 --cab-dim 256 --decoder-dim 128 --nlayers 1 --sample-type random --num-ref-points 128 --experiment-id 8938992\n",
      "(50000, 200, 9) (25000, 200, 9) (25000, 200, 9)\n",
      "test_prediction.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  chp = torch.load(f'./saved_models/{args.dataset}_{args.experiment_id}.h5')\n",
      "Number of points to predict:  tensor(332, device='cuda:0')\n",
      "Number of points to predict:  tensor(301, device='cuda:0')\n",
      "Number of points to predict:  tensor(318, device='cuda:0')\n",
      "Number of points to predict:  tensor(337, device='cuda:0')\n",
      "Number of points to predict:  tensor(302, device='cuda:0')\n",
      "Number of points to predict:  tensor(323, device='cuda:0')\n",
      "Number of points to predict:  tensor(327, device='cuda:0')\n",
      "Number of points to predict:  tensor(307, device='cuda:0')\n",
      "Number of points to predict:  tensor(303, device='cuda:0')\n",
      "Number of points to predict:  tensor(320, device='cuda:0')\n",
      "Number of points to predict:  tensor(352, device='cuda:0')\n",
      "Number of points to predict:  tensor(320, device='cuda:0')\n",
      "Number of points to predict:  tensor(361, device='cuda:0')\n",
      "Number of points to predict:  tensor(341, device='cuda:0')\n",
      "Number of points to predict:  tensor(315, device='cuda:0')\n",
      "Number of points to predict:  tensor(315, device='cuda:0')\n",
      "Number of points to predict:  tensor(324, device='cuda:0')\n",
      "Number of points to predict:  tensor(333, device='cuda:0')\n",
      "Number of points to predict:  tensor(332, device='cuda:0')\n",
      "Number of points to predict:  tensor(334, device='cuda:0')\n",
      "Number of points to predict:  tensor(307, device='cuda:0')\n",
      "Number of points to predict:  tensor(318, device='cuda:0')\n",
      "Number of points to predict:  tensor(318, device='cuda:0')\n",
      "Number of points to predict:  tensor(320, device='cuda:0')\n",
      "Number of points to predict:  tensor(305, device='cuda:0')\n",
      "Number of points to predict:  tensor(313, device='cuda:0')\n",
      "Number of points to predict:  tensor(307, device='cuda:0')\n",
      "Number of points to predict:  tensor(325, device='cuda:0')\n",
      "Number of points to predict:  tensor(294, device='cuda:0')\n",
      "Number of points to predict:  tensor(316, device='cuda:0')\n",
      "Number of points to predict:  tensor(305, device='cuda:0')\n",
      "Number of points to predict:  tensor(316, device='cuda:0')\n",
      "Number of points to predict:  tensor(316, device='cuda:0')\n",
      "Number of points to predict:  tensor(331, device='cuda:0')\n",
      "Number of points to predict:  tensor(304, device='cuda:0')\n",
      "Number of points to predict:  tensor(350, device='cuda:0')\n",
      "Number of points to predict:  tensor(316, device='cuda:0')\n",
      "Number of points to predict:  tensor(338, device='cuda:0')\n",
      "Number of points to predict:  tensor(337, device='cuda:0')\n",
      "Number of points to predict:  tensor(335, device='cuda:0')\n",
      "Number of points to predict:  tensor(323, device='cuda:0')\n",
      "Number of points to predict:  tensor(318, device='cuda:0')\n",
      "Number of points to predict:  tensor(340, device='cuda:0')\n",
      "Number of points to predict:  tensor(310, device='cuda:0')\n",
      "Number of points to predict:  tensor(321, device='cuda:0')\n",
      "Number of points to predict:  tensor(331, device='cuda:0')\n",
      "Number of points to predict:  tensor(327, device='cuda:0')\n",
      "Number of points to predict:  tensor(311, device='cuda:0')\n",
      "Number of points to predict:  tensor(314, device='cuda:0')\n",
      "Number of points to predict:  tensor(332, device='cuda:0')\n",
      "Number of points to predict:  tensor(322, device='cuda:0')\n",
      "Length of means 322\n",
      "Length of channel indices 322\n",
      "Interpolation of Channel:  0\n",
      "Amount of points to predict:  81 for channel:  0\n",
      "Length of means:  81\n",
      "Most frequent value: -13.153415\n",
      "Count: 2\n",
      "Mean of the means:  1.2998877\n",
      "Time indices of artefacts:  [189 191]\n",
      "Length of this array of indices:  2\n",
      "Interpolation of Channel:  1\n",
      "Amount of points to predict:  85 for channel:  1\n",
      "Length of means:  85\n",
      "Most frequent value: -9.750884\n",
      "Count: 2\n",
      "Mean of the means:  2.0838883\n",
      "Time indices of artefacts:  [49 50]\n",
      "Length of this array of indices:  2\n",
      "Interpolation of Channel:  2\n",
      "Amount of points to predict:  79 for channel:  2\n",
      "Length of means:  79\n",
      "Most frequent value: -33.812233\n",
      "Count: 2\n",
      "Mean of the means:  -23.53037\n",
      "Time indices of artefacts:  [136 139]\n",
      "Length of this array of indices:  2\n",
      "Interpolation of Channel:  3\n",
      "Amount of points to predict:  77 for channel:  3\n",
      "Length of means:  77\n",
      "Most frequent value: -2.363908\n",
      "Count: 1\n",
      "Mean of the means:  4.797552\n",
      "Time indices of artefacts:  [39]\n",
      "Length of this array of indices:  1\n",
      "Total pred points is: 322\n"
     ]
    }
   ],
   "source": [
    "!python test_prediction.py --batch-size 60 --dataset randomwalk --norm --shuffle --sample-tp 0.1 --mse-weight 1.0 --imab-dim 64 --cab-dim 256 --decoder-dim 128 --nlayers 1 --sample-type random --num-ref-points 128 --experiment-id 8938992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_prediction.py --niters 1 --batch-size 20 --dataset sgrA --norm --shuffle --sample-tp 0.1 --mse-weight 1.0 --imab-dim 64 --cab-dim 256 --decoder-dim 128 --nlayers 1 --sample-type random --num-ref-points 128 --experiment-id 982081\n",
      "(6300, 960, 9) (1260, 960, 9) (840, 960, 9)\n",
      "test_prediction.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  chp = torch.load(f'./saved_models/{args.dataset}_{args.experiment_id}.h5')\n",
      "Number of points to predict:  tensor(1967, device='cuda:0')\n",
      "Number of points to predict:  tensor(2012, device='cuda:0')\n",
      "Number of points to predict:  tensor(1968, device='cuda:0')\n",
      "Number of points to predict:  tensor(1976, device='cuda:0')\n",
      "Number of points to predict:  tensor(1983, device='cuda:0')\n",
      "Number of points to predict:  tensor(1980, device='cuda:0')\n",
      "Number of points to predict:  tensor(1971, device='cuda:0')\n",
      "Number of points to predict:  tensor(1985, device='cuda:0')\n",
      "Number of points to predict:  tensor(1981, device='cuda:0')\n",
      "Number of points to predict:  tensor(2007, device='cuda:0')\n",
      "Number of points to predict:  tensor(1973, device='cuda:0')\n",
      "Number of points to predict:  tensor(1994, device='cuda:0')\n",
      "Number of points to predict:  tensor(1979, device='cuda:0')\n",
      "Number of points to predict:  tensor(1991, device='cuda:0')\n",
      "Number of points to predict:  tensor(1975, device='cuda:0')\n",
      "Number of points to predict:  tensor(1998, device='cuda:0')\n",
      "Number of points to predict:  tensor(1971, device='cuda:0')\n",
      "Number of points to predict:  tensor(1968, device='cuda:0')\n",
      "Number of points to predict:  tensor(1954, device='cuda:0')\n",
      "Number of points to predict:  tensor(1966, device='cuda:0')\n",
      "Number of points to predict:  tensor(2000, device='cuda:0')\n",
      "Number of points to predict:  tensor(2000, device='cuda:0')\n",
      "Number of points to predict:  tensor(1981, device='cuda:0')\n",
      "Number of points to predict:  tensor(1980, device='cuda:0')\n",
      "Number of points to predict:  tensor(1967, device='cuda:0')\n",
      "Number of points to predict:  tensor(1968, device='cuda:0')\n",
      "Number of points to predict:  tensor(1997, device='cuda:0')\n",
      "Number of points to predict:  tensor(1990, device='cuda:0')\n",
      "Number of points to predict:  tensor(2002, device='cuda:0')\n",
      "Number of points to predict:  tensor(2006, device='cuda:0')\n",
      "Number of points to predict:  tensor(1988, device='cuda:0')\n",
      "Number of points to predict:  tensor(2006, device='cuda:0')\n",
      "Number of points to predict:  tensor(1980, device='cuda:0')\n",
      "Number of points to predict:  tensor(1976, device='cuda:0')\n",
      "Number of points to predict:  tensor(1973, device='cuda:0')\n",
      "Number of points to predict:  tensor(1980, device='cuda:0')\n",
      "Number of points to predict:  tensor(2008, device='cuda:0')\n",
      "Number of points to predict:  tensor(1988, device='cuda:0')\n",
      "Number of points to predict:  tensor(2008, device='cuda:0')\n",
      "Number of points to predict:  tensor(1996, device='cuda:0')\n",
      "Number of points to predict:  tensor(1955, device='cuda:0')\n",
      "Number of points to predict:  tensor(1976, device='cuda:0')\n",
      "Number of points to predict:  tensor(1994, device='cuda:0')\n",
      "Number of points to predict:  tensor(1972, device='cuda:0')\n",
      "Number of points to predict:  tensor(1998, device='cuda:0')\n",
      "Number of points to predict:  tensor(1964, device='cuda:0')\n",
      "Number of points to predict:  tensor(1992, device='cuda:0')\n",
      "Number of points to predict:  tensor(1949, device='cuda:0')\n",
      "Number of points to predict:  tensor(1993, device='cuda:0')\n",
      "Number of points to predict:  tensor(1959, device='cuda:0')\n",
      "Number of points to predict:  tensor(2006, device='cuda:0')\n",
      "Length of means 2006\n",
      "Length of channel indices 2006\n",
      "Interpolation of Channel:  0\n",
      "Amount of points to predict:  810 for channel:  0\n",
      "Length of means:  810\n",
      "Most frequent value: 0.302166\n",
      "Count: 166\n",
      "Mean of the means:  0.35499638\n",
      "Time indices of artefacts:  [  0   1   3   5  17  23  25  26  28  30  34  37  43  47  48  67  69  75\n",
      "  82  83  92  94  98 100 101 113 119 121 123 124 127 131 134 136 142 150\n",
      " 154 156 161 162 165 177 180 186 197 199 206 209 212 215 216 217 221 222\n",
      " 226 231 233 261 287 293 297 302 303 309 311 318 319 324 326 327 332 344\n",
      " 357 381 382 383 385 387 391 393 398 407 416 426 429 431 437 441 455 466\n",
      " 470 472 488 494 503 513 515 520 524 525 527 534 548 580 586 588 602 603\n",
      " 604 616 624 628 633 657 711 712 713 721 727 728 730 731 738 757 767 776\n",
      " 778 782 784 789 803 806 807 809 810 812 817 829 833 835 838 839 859 861\n",
      " 868 870 872 883 884 885 887 892 895 900 901 903 904 907 908 910 911 925\n",
      " 937 940 950 951]\n",
      "Length of this array of indices:  166\n",
      "Interpolation of Channel:  1\n",
      "Amount of points to predict:  192 for channel:  1\n",
      "Length of means:  192\n",
      "Most frequent value: 0.26869354\n",
      "Count: 36\n",
      "Mean of the means:  0.41871002\n",
      "Time indices of artefacts:  [  5  25  98 119 123 127 131 206 209 261 287 318 319 327 382 400 466 470\n",
      " 494 525 527 537 576 577 580 586 588 604 666 757 767 784 838 859 895 937]\n",
      "Length of this array of indices:  36\n",
      "Interpolation of Channel:  2\n",
      "Amount of points to predict:  812 for channel:  2\n",
      "Length of means:  812\n",
      "Most frequent value: 0.48758936\n",
      "Count: 168\n",
      "Mean of the means:  0.3484179\n",
      "Time indices of artefacts:  [  0   1   3   5  17  23  25  26  28  30  37  39  43  47  48  67  69  75\n",
      "  82  83  92  94  98 100 101 113 119 121 123 124 127 131 134 136 142 150\n",
      " 154 156 161 162 165 167 177 180 186 197 199 206 209 212 215 216 217 221\n",
      " 222 226 231 233 261 287 293 297 302 303 309 311 318 319 324 326 327 347\n",
      " 357 378 387 388 390 391 400 416 422 429 431 437 441 445 455 466 470 494\n",
      " 503 515 524 525 527 531 533 534 537 548 553 567 574 586 588 598 603 610\n",
      " 627 633 642 643 651 657 666 680 711 712 713 727 735 738 747 757 758 767\n",
      " 776 777 778 782 784 789 803 806 807 809 810 812 817 829 833 835 838 839\n",
      " 859 861 868 870 872 883 884 885 887 889 892 895 900 901 903 904 907 908\n",
      " 910 911 925 937 940 951]\n",
      "Length of this array of indices:  168\n",
      "Interpolation of Channel:  3\n",
      "Amount of points to predict:  192 for channel:  3\n",
      "Length of means:  192\n",
      "Most frequent value: 0.3666691\n",
      "Count: 192\n",
      "/home/gsasseville/.local/share/virtualenvs/Tripletformer-nUF7tw2u/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/gsasseville/.local/share/virtualenvs/Tripletformer-nUF7tw2u/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Mean of the means:  nan\n",
      "Time indices of artefacts:  [  1   3   5  17  23  25  26  28  30  37  43  47  48  67  69  75  82  83\n",
      "  92  94  98 100 101 113 119 121 123 124 127 131 134 136 142 150 154 156\n",
      " 161 162 165 177 180 186 197 199 206 209 212 215 216 217 221 222 226 231\n",
      " 233 261 287 293 297 302 303 309 311 318 319 324 326 327 332 344 347 357\n",
      " 378 381 382 383 385 387 388 390 391 393 398 400 407 416 422 429 431 437\n",
      " 441 445 455 466 470 472 488 494 500 503 513 515 520 524 525 527 531 533\n",
      " 534 537 548 553 567 574 576 577 580 582 586 588 598 602 603 604 616 624\n",
      " 626 627 628 633 643 651 657 666 680 711 712 713 721 727 728 729 730 731\n",
      " 733 735 738 747 757 758 767 776 777 778 782 784 789 803 806 807 809 810\n",
      " 812 817 829 833 835 838 839 859 861 868 870 872 883 884 885 887 892 895\n",
      " 900 901 903 904 907 908 910 911 925 937 940 951]\n",
      "Length of this array of indices:  192\n",
      "Total pred points is: 2006\n"
     ]
    }
   ],
   "source": [
    "!python test_prediction.py --niters 1 --batch-size 20 --dataset sgrA --norm --shuffle --sample-tp 0.1 --mse-weight 1.0 --imab-dim 64 --cab-dim 256 --decoder-dim 128 --nlayers 1 --sample-type random --num-ref-points 128 --experiment-id 982081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing elements in array 1: [  0  39 167 610 642 889]\n",
      "All elements of array 2 are found in the main array.\n",
      "Missing elements in array 3: [  0  34 426 950]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Main array of integers\n",
    "main_array = np.array([\n",
    "    1, 3, 5, 17, 23, 25, 26, 28, 30, 37, 43, 47, 48, 67, 69, 75, 82, 83,\n",
    "    92, 94, 98, 100, 101, 113, 119, 121, 123, 124, 127, 131, 134, 136,\n",
    "    142, 150, 154, 156, 161, 162, 165, 177, 180, 186, 197, 199, 206, 209,\n",
    "    212, 215, 216, 217, 221, 222, 226, 231, 233, 261, 287, 293, 297, 302,\n",
    "    303, 309, 311, 318, 319, 324, 326, 327, 332, 344, 347, 357, 378, 381,\n",
    "    382, 383, 385, 387, 388, 390, 391, 393, 398, 400, 407, 416, 422, 429,\n",
    "    431, 437, 441, 445, 455, 466, 470, 472, 488, 494, 500, 503, 513, 515,\n",
    "    520, 524, 525, 527, 531, 533, 534, 537, 548, 553, 567, 574, 576, 577,\n",
    "    580, 582, 586, 588, 598, 602, 603, 604, 616, 624, 626, 627, 628, 633,\n",
    "    643, 651, 657, 666, 680, 711, 712, 713, 721, 727, 728, 729, 730, 731,\n",
    "    733, 735, 738, 747, 757, 758, 767, 776, 777, 778, 782, 784, 789, 803,\n",
    "    806, 807, 809, 810, 812, 817, 829, 833, 835, 838, 839, 859, 861, 868,\n",
    "    870, 872, 883, 884, 885, 887, 892, 895, 900, 901, 903, 904, 907, 908,\n",
    "    910, 911, 925, 937, 940, 951\n",
    "])\n",
    "\n",
    "# Arrays to check\n",
    "arrays_to_check = [\n",
    "    np.array([\n",
    "        0, 1, 3, 5, 17, 23, 25, 26, 28, 30, 37, 39, 43, 47, 48, 67, 69, 75,\n",
    "        82, 83, 92, 94, 98, 100, 101, 113, 119, 121, 123, 124, 127, 131, 134,\n",
    "        136, 142, 150, 154, 156, 161, 162, 165, 167, 177, 180, 186, 197, 199,\n",
    "        206, 209, 212, 215, 216, 217, 221, 222, 226, 231, 233, 261, 287, 293,\n",
    "        297, 302, 303, 309, 311, 318, 319, 324, 326, 327, 347, 357, 378, 387,\n",
    "        388, 390, 391, 400, 416, 422, 429, 431, 437, 441, 445, 455, 466, 470,\n",
    "        494, 503, 515, 524, 525, 527, 531, 533, 534, 537, 548, 553, 567, 574,\n",
    "        586, 588, 598, 603, 610, 627, 633, 642, 643, 651, 657, 666, 680, 711,\n",
    "        712, 713, 727, 735, 738, 747, 757, 758, 767, 776, 777, 778, 782, 784,\n",
    "        789, 803, 806, 807, 809, 810, 812, 817, 829, 833, 835, 838, 839, 859,\n",
    "        861, 868, 870, 872, 883, 884, 885, 887, 889, 892, 895, 900, 901, 903,\n",
    "        904, 907, 908, 910, 911, 925, 937, 940, 951\n",
    "    ]),\n",
    "    np.array([\n",
    "        5, 25, 98, 119, 123, 127, 131, 206, 209, 261, 287, 318, 319, 327,\n",
    "        382, 400, 466, 470, 494, 525, 527, 537, 576, 577, 580, 586, 588,\n",
    "        604, 666, 757, 767, 784, 838, 859, 895, 937\n",
    "    ]),\n",
    "    np.array([\n",
    "        0, 1, 3, 5, 17, 23, 25, 26, 28, 30, 34, 37, 43, 47, 48, 67, 69, 75,\n",
    "        82, 83, 92, 94, 98, 100, 101, 113, 119, 121, 123, 124, 127, 131, 134,\n",
    "        136, 142, 150, 154, 156, 161, 162, 165, 177, 180, 186, 197, 199, 206,\n",
    "        209, 212, 215, 216, 217, 221, 222, 226, 231, 233, 261, 287, 293, 297,\n",
    "        302, 303, 309, 311, 318, 319, 324, 326, 327, 332, 344, 357, 381, 382,\n",
    "        383, 385, 387, 391, 393, 398, 407, 416, 426, 429, 431, 437, 441, 455,\n",
    "        466, 470, 472, 488, 494, 503, 513, 515, 520, 524, 525, 527, 534, 548,\n",
    "        580, 586, 588, 602, 603, 604, 616, 624, 628, 633, 657, 711, 712, 713,\n",
    "        721, 727, 728, 730, 731, 738, 757, 767, 776, 778, 782, 784, 789, 803,\n",
    "        806, 807, 809, 810, 812, 817, 829, 833, 835, 838, 839, 859, 861, 868,\n",
    "        870, 872, 883, 884, 885, 887, 892, 895, 900, 901, 903, 904, 907, 908,\n",
    "        910, 911, 925, 937, 940, 950, 951\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Check each array and find missing elements\n",
    "for idx, array in enumerate(arrays_to_check):\n",
    "    missing_elements = array[~np.isin(array, main_array)]\n",
    "    if len(missing_elements) > 0:\n",
    "        print(f\"Missing elements in array {idx + 1}: {missing_elements}\")\n",
    "    else:\n",
    "        print(f\"All elements of array {idx + 1} are found in the main array.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tripletformer-nUF7tw2u",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
