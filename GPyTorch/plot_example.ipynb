{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import *\n",
    "from trainer import Trainer\n",
    "from evaluator import Evaluator\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgra\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNIR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m num_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(keys)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "data = get_dataset('sgra')\n",
    "keys = [\"X\", 'NIR', \"IR\", \"submm\"]\n",
    "num_keys = len(keys)\n",
    "iterations = 1000\n",
    "max_early_stop = 30\n",
    "\n",
    "print(f'Dataset has {len(data)} samples')\n",
    "\n",
    "# for idx, sample in enumerate(tqdm(data)):\n",
    "#     # Process the data\n",
    "#     train_x, train_idx, train_y, test_x, test_y, test_idx = process_data(sample, keys)\n",
    "#     full_train_x = torch.cat(train_x)\n",
    "#     full_train_idx = torch.cat(train_idx)\n",
    "#     full_train_y = torch.cat(train_y)\n",
    "\n",
    "#     # Train the model\n",
    "#     trainer = Trainer(full_train_x, full_train_idx, full_train_y, 'gaussian', iterations=iterations, max_early_stop=max_early_stop)\n",
    "#     model, likelihood = trainer.train_model()\n",
    "\n",
    "#     evaluator = Evaluator(model, likelihood, test_x, test_idx, num_keys)\n",
    "#     observed_preds = evaluator.evaluate()\n",
    "\n",
    "#     # Initialize plots\n",
    "#     f, axes = plt.subplots(num_keys, 1, figsize=(num_keys * 6, num_keys * 3))\n",
    "#     if num_keys == 1:\n",
    "#         axes = [axes]\n",
    "\n",
    "#     sample_results = {\"sample_index\": idx}\n",
    "#     mse_total = 0\n",
    "#     crps_total = 0\n",
    "\n",
    "#     for i in range(num_keys):\n",
    "#         # Convert to numpy\n",
    "#         train_xi = train_x[i].detach().numpy()\n",
    "#         train_yi = train_y[i].detach().numpy()\n",
    "#         test_xi = test_x[i].detach().numpy()\n",
    "#         test_yi = test_y[i].detach().numpy()\n",
    "\n",
    "#         means = observed_preds[i].mean.cpu().detach().numpy()\n",
    "#         lower, upper = observed_preds[i].confidence_region()\n",
    "#         lower, upper = lower.detach().cpu().numpy(), upper.cpu().detach().numpy()\n",
    "#         standard_deviations = (upper - means) / 2.0\n",
    "\n",
    "#         ax = axes[i]\n",
    "#         ax_plot(ax, train_yi, train_xi, test_yi, test_xi, means, lower, upper, f'Observed Values (Likelihood) - Task {keys[i]}')\n",
    "\n",
    "#         # Calculate metrics\n",
    "#         crps = crps_norm(test_yi, means, standard_deviations)\n",
    "#         mse = mean_squared_error(test_yi, means)\n",
    "#         mse_total += mse\n",
    "#         crps_total += crps\n",
    "\n",
    "#         # Save metrics for the key\n",
    "#         sample_results[f\"mse_{keys[i]}\"] = mse\n",
    "#         sample_results[f\"crps_{keys[i]}\"] = crps\n",
    "\n",
    "#     # Save averaged metrics\n",
    "#     sample_results[\"average_mse\"] = mse_total / num_keys\n",
    "#     sample_results[\"average_crps\"] = crps_total / num_keys\n",
    "#     results.append(sample_results)\n",
    "\n",
    "#     # Save the plot\n",
    "#     plot_path = f\"plots/sample_{idx}.png\"\n",
    "#     plt.savefig(plot_path)\n",
    "#     plt.close()\n",
    "\n",
    "# # Save results to a CSV file\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "# print(\"Processing complete. Results saved to 'results.csv' and plots saved to the 'plots/' directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPyTorch-L0I7ISKI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
