{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9471/4001594433.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model path: save/sgra_fold0_14_20250403_134958/best_model.pth\n",
      "Model losses:\n",
      "  sgra_fold0_13_20250403_135329: 45.67409662902355\n",
      "  sgra_fold0_5_20250403_131713: 46.16662035882473\n",
      "  sgra_fold0_11_20250403_134231: 72.1814873367548\n",
      "  sgra_fold0_8_20250403_132651: 47.306783854961395\n",
      "  sgra_fold0_1_20250403_131714: 47.64918717741966\n",
      "  sgra_fold0_3_20250403_131713: 72.03574284911156\n",
      "  sgra_fold0_6_20250403_133742: 46.412629410624504\n",
      "  sgra_fold0_4_20250403_131714: 59.40389084815979\n",
      "  sgra_fold0_14_20250403_134958: 45.346777737140656\n",
      "  sgra_fold0_9_20250403_132649: 48.37328949570656\n",
      "  sgra_fold0_7_20250403_132025: 47.41524352133274\n",
      "  sgra_fold0_2_20250403_131714: 47.98417070508003\n",
      "  sgra_fold0_15_20250403_160151: 65.59162385761738\n",
      "  sgra_fold0_16_20250403_160255: 64.0322804003954\n",
      "  sgra_fold0_12_20250403_135004: 68.89293368160725\n",
      "  sgra_fold0_10_20250403_134232: 48.88146764039993\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "\n",
    "def find_best_model_and_losses(directory=\"save\"):\n",
    "    \"\"\"\n",
    "    Finds the best model among 16 trained models based on their validation losses.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory containing the model folders.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best model's path and a dictionary of all model losses.\n",
    "    \"\"\"\n",
    "\n",
    "    model_losses = {}\n",
    "    best_model_path = None\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    # Regular expression to match folder names\n",
    "    folder_pattern = re.compile(r\"sgra_fold0_\\d+_\\d{8}_\\d{6}\")\n",
    "\n",
    "    # Iterate through all subdirectories in the given directory\n",
    "    for folder_name in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder_name)\n",
    "\n",
    "        # Check if the path is a directory and matches the folder name pattern\n",
    "        if os.path.isdir(folder_path) and folder_pattern.match(folder_name):\n",
    "            model_file_path = os.path.join(folder_path, \"best_model.pth\")\n",
    "\n",
    "            # Check if the model file exists\n",
    "            if os.path.exists(model_file_path):\n",
    "                try:\n",
    "                    checkpoint = torch.load(model_file_path)\n",
    "                    loss = checkpoint['loss']\n",
    "                    model_losses[folder_name] = loss\n",
    "\n",
    "                    # Update best model if current loss is lower\n",
    "                    if loss < best_loss:\n",
    "                        best_loss = loss\n",
    "                        best_model_path = model_file_path\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading model from {model_file_path}: {e}\")\n",
    "\n",
    "    return best_model_path, model_losses\n",
    "\n",
    "def print_best_model_and_losses(directory=\"save\"):\n",
    "    \"\"\"\n",
    "    Prints the best model path and all model losses.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory containing the model folders.\n",
    "    \"\"\"\n",
    "    best_model_path, model_losses = find_best_model_and_losses(directory)\n",
    "\n",
    "    if best_model_path:\n",
    "        print(f\"Best model path: {best_model_path}\")\n",
    "        print(\"Model losses:\")\n",
    "        for model_name, loss in model_losses.items():\n",
    "            print(f\"  {model_name}: {loss}\")\n",
    "    else:\n",
    "        print(\"No valid models found.\")\n",
    "\n",
    "# Example usage:\n",
    "print_best_model_and_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='base.yaml', device='cuda:0', seed=1, testmissingratio=0.1, nfold=0, unconditional=False, gp_noise=True, modelfolder='sgra_fold0_final_20250404_110307', nsample=100)\n",
      "{\n",
      "    \"train\": {\n",
      "        \"epochs\": 1,\n",
      "        \"batch_size\": 16,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"diffusion\": {\n",
      "        \"layers\": 8,\n",
      "        \"channels\": 128,\n",
      "        \"nheads\": 8,\n",
      "        \"diffusion_embedding_dim\": 256,\n",
      "        \"beta_start\": 0.0001,\n",
      "        \"beta_end\": 0.5,\n",
      "        \"num_steps\": 50,\n",
      "        \"schedule\": \"quad\"\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"is_unconditional\": false,\n",
      "        \"timeemb\": 128,\n",
      "        \"featureemb\": 16,\n",
      "        \"target_strategy\": \"random\",\n",
      "        \"test_missing_ratio\": 0.1\n",
      "    }\n",
      "}\n",
      "/home/gsasseville/.local/share/virtualenvs/Diffusion-Nf9kVZlp/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Loading pre-trained model from folder: ./save/sgra_fold0_final_20250404_110307/model.pth\n",
      "/home/gsasseville/Files/UDEM/Maitrise/SgrA/SgrA_Interpolation/Diffusion/exe_sgra.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"./save/\" + args.modelfolder + \"/model.pth\")\n",
      "Evaluating Model\n",
      "eval_mask[:, feature_idx].bool() tensor([False, False, False,  ..., False, False, False])\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() [-1.1329057  -1.1340879  -0.15247424  0.8308988  -0.14965835 -0.15176082\n",
      " -0.15173784 -1.1290559  -1.1306194  -1.1323326   0.5053259  -0.47694284\n",
      " -0.4776199   2.1435223   2.1463327   0.50270325  0.504127    0.5065464\n",
      "  0.1780656   0.17818199  0.1776922   1.8128796   2.4620082   2.4700983\n",
      "  0.17978846  0.17860691  0.17778818 -0.15088698 -0.1496682  -0.47803596\n",
      " -0.47847265 -0.47864795 -0.47896713 -0.8098023  -0.81029856 -0.15134294\n",
      " -0.15094681 -0.14971796 -0.8092103  -0.8084682  -0.15027104 -0.15053564\n",
      " -0.15050277 -0.80868095 -0.8100197  -0.8103086  -0.8092177  -0.47962183\n",
      " -0.47904605 -0.8082553  -0.8097852  -0.15127687 -0.14944962 -0.14948326\n",
      " -0.1506364  -0.48061374 -0.4791101   0.1767852   0.17765504 -0.4786923\n",
      " -0.47910172  0.5060803   1.1508847   1.1596876   0.5068464   0.50483507\n",
      "  0.83299696 -0.8106435  -0.8100286   0.83134824  0.83126074  0.17861882\n",
      " -0.80940753 -0.8096455  -0.8108241  -0.8105348   0.17963028  0.5059243\n",
      "  0.50630563  0.50792164 -0.4777733  -0.15136749 -0.14967163  0.17700525\n",
      " -0.4783274  -0.47771037 -0.47932282 -0.48010394 -0.4808719  -0.808897\n",
      " -0.809168   -1.1333477  -1.1334528  -1.134229   -1.134327   -1.1345748\n",
      " -1.1342863  -0.15032777 -1.1319101  -1.1314656  -0.15263441 -0.1519646\n",
      " -0.47942176  0.8264166   0.82742757  0.83030415  0.83237326 -0.14752781\n",
      " -0.14838275 -0.14898182 -1.1345246   0.50636154  0.5061915   0.5036226\n",
      " -0.8121515  -0.8125654  -0.8113726  -0.8093537  -0.15199345 -0.15125607\n",
      " -0.15037926 -0.14908431  0.5053815   0.5054893  -0.14983718 -0.14992283\n",
      " -0.15030035 -0.1513458  -0.15134016 -0.150666   -0.4801015  -0.47801828\n",
      " -0.47775984 -0.47776312 -0.4785722  -0.47790262 -0.4779136  -0.47758293\n",
      " -1.1323907   0.5051203   0.5066406   0.5065262  -0.47979107 -0.47979698\n",
      " -0.48037252 -0.48026556 -0.48103258 -0.47963095 -0.479609   -0.478497\n",
      " -0.47965923 -1.1315696  -1.1362191  -0.8108728  -0.8103312  -0.8108186\n",
      " -0.80942273 -0.809189   -0.8059746  -0.80476665 -0.8047041  -0.80883217\n",
      " -0.80956113 -0.4766285  -0.47525507 -0.4755894  -0.47641978 -0.4799574\n",
      " -0.8106485  -0.81033796  0.17867082 -0.15253301 -0.8085148  -0.8081144\n",
      " -0.80799115 -0.80891615 -0.81129485 -0.81144446 -0.8110713  -0.812154\n",
      " -0.8121172  -0.81130254 -0.8057138  -0.8051247  -0.8027191  -0.80320597\n",
      " -0.8005087  -0.8083289  -0.809025   -1.134118   -1.1354814  -1.1361738\n",
      " -0.14950608 -0.15028407 -0.47885576 -0.47957474 -0.47997993 -0.14901704\n",
      " -0.15054987 -0.8101618  -0.81088    -0.47923744 -0.47939992 -0.4785603\n",
      " -0.8094279  -0.47835752 -0.477986   -0.47850105 -0.47914234 -0.47943723\n",
      " -0.47993034 -0.4797278  -1.1318427  -0.47906345 -0.47872937  0.18150866\n",
      "  0.17749894  0.17672251 -0.15200672 -0.47803167 -0.47904694 -0.4797227\n",
      " -0.47920313 -0.4795327  -0.4786335   0.1788008   0.17818427 -0.80983967\n",
      " -0.80977863 -0.15014786 -0.1513999  -0.15151887 -0.1523938  -0.15203077\n",
      " -0.8090526  -0.8105414  -0.81039447 -0.8114636  -0.47894526 -0.47852838\n",
      " -0.47770956  0.50715536  0.5081223   0.18067715 -0.4777085  -0.477927\n",
      "  1.1570871   1.1557015   1.1563805   1.1584603   1.158384    0.50750744\n",
      "  2.7976406   2.7942274   2.7900152   5.1006713   5.082222    5.05845\n",
      "  4.1135697   5.748458    5.7498374   5.7593145   3.4622805   3.4510036\n",
      "  3.4430425   2.4631698   2.4640563   1.8117706   1.8104548   1.8007585\n",
      " -0.47875652 -0.47916692 -0.4794442  -0.47943726  0.18039283  0.1793228\n",
      "  0.17860968 -0.8097632  -0.8089085  -0.80858433 -0.15146524 -0.15200616\n",
      " -0.1519105   0.50496083  0.50584805  0.5065296  -0.15135443 -1.1327534\n",
      " -1.1327091  -0.80998826 -0.8071906  -0.80724156  0.1800135  -0.15139367\n",
      " -0.15218163 -1.1344303  -1.1332802  -1.1319824  -0.4787955  -0.47886017\n",
      " -0.48006082 -0.80872357 -0.8093562  -0.8096797  -0.47965702 -1.1352414\n",
      " -1.1352537  -1.1339508  -0.15046623 -0.15018259 -0.47764823 -0.47781086\n",
      " -0.4786081  -0.47793412 -0.4784402  -1.1347265  -1.1352949  -1.1340591\n",
      " -0.14993794 -0.15018362 -0.1501926  -0.15005562 -0.15019439 -0.15123521\n",
      " -0.15302016 -1.1366122  -1.1353064  -1.1328323  -0.4786868  -0.4791589\n",
      " -0.80874765 -0.8078618  -0.4804607  -0.48131764 -0.4805658  -0.47912443\n",
      "  0.51228446  0.5103426   0.50850266  0.5067575   0.18014169  0.17858773\n",
      "  0.17819417  0.17780389  0.18019238  0.50806105  0.5061478   0.50438243\n",
      "  0.17874047  0.17742985  2.7965126   2.7894886   1.1542169   1.1565591\n",
      "  1.1558845   1.1518507   1.1531413   1.155995   -0.47896922 -0.4807279\n",
      " -0.15491062 -0.15312304 -0.1512062  -0.4788431  -0.47765994  1.1580042\n",
      "  0.5003977   0.50206125  0.50482297  0.5084181   0.5053332   0.8295542\n",
      "  0.8344173   2.1390562   2.1370664   0.50549203  1.8092024   1.8108935\n",
      "  1.8108745   0.17666714  0.17676723  0.17698734  1.4850519   1.4818596\n",
      "  1.4792968   1.4784623  -0.47935823 -0.47875994  0.17759943  0.17820087\n",
      " -0.15165688 -0.8085611  -0.8098818  -0.81058013  0.5106142   0.5100768\n",
      "  0.50954545  0.50912094 -0.80779165 -0.8073588  -0.8069757  -0.4778167\n",
      " -0.47880062 -0.47943658  0.17992543  0.17861676  0.17733747 -0.8100989\n",
      " -0.809649   -0.80967104 -0.8097291  -0.47983232 -1.1366099  -1.1372107\n",
      "  0.17781615 -0.8095304  -0.808526   -0.80943483 -0.8098351  -0.15092278\n",
      " -0.15069665  0.8327153   0.8312174   0.83186394  0.8326662  -0.15274331\n",
      " -0.15200403 -0.15087523  0.50584924  1.4853652   1.4851224   0.5061917\n",
      "  1.4821073   1.1565518   1.155966    1.1525431   0.8311303   0.8338435\n",
      " -0.14634429 -0.14487053 -0.14558841 -0.14688163 -0.14736699  0.5063136\n",
      "  0.50723773  0.83095556  2.1377294   2.4673848  -0.15253465  0.83157235\n",
      "  0.8315532   0.8299316   0.50273395  0.5022687   0.17926931  0.18173884\n",
      "  0.18294443  0.18580638  0.50702673  0.50562656 -0.80838877 -0.8085468\n",
      " -0.8073039  -0.15155856 -0.15097441 -1.1334642  -1.1344149  -1.1344438\n",
      " -1.1325111  -0.47840402 -0.47885847 -0.4785     -0.47839254 -0.8102422\n",
      " -0.8094638  -0.15109158 -0.15217946 -0.15168992  0.50384486 -0.4807324\n",
      " -0.48049328 -0.47927403 -0.15295161 -0.15128446 -0.15051568 -0.4791629\n",
      " -0.47842175 -0.47713992  0.17715584  0.17774768  0.8338565   0.8363395\n",
      "  0.8365802  -0.151357   -0.15172513  0.5042822  -1.1321338  -1.1328714\n",
      "  1.4869865   1.4851639   1.483432    0.5089314   0.50829643  1.4825386\n",
      "  1.4893366   1.8147633   1.8144163   1.1532822   1.1532303   2.8033652\n",
      "  2.806949   -0.14992796 -0.15057863  0.50628424  0.5052385   0.5052258\n",
      "  0.507067    0.5059233  -0.15145342 -0.1505508  -1.1378895  -1.1378022\n",
      " -0.48017207 -0.48111874 -0.4807229  -0.48016948 -0.47852218 -0.4782966\n",
      " -0.47874472 -0.4793644  -0.47919193 -0.47918805 -1.1344526  -1.1341946\n",
      " -1.1333404  -0.47830403 -1.1335088  -1.134758   -1.1305068  -1.1302506\n",
      " -1.1321518  -1.1353755  -0.80767596 -0.8065673  -0.8071389  -0.8070485\n",
      " -0.8064666  -0.81056726 -0.15111107  0.50596434 -0.47870886 -0.8090943\n",
      " -0.81059164 -0.81121415  0.5083856   0.50250024  1.8101712   1.8090047\n",
      "  1.8071665  -0.80917776 -0.80967885 -0.8081306  -0.47861743 -0.47896034\n",
      " -0.4810368  -0.48113316 -0.47772655 -0.47818187 -0.47921282 -0.47929472\n",
      "  0.17888504  0.18017602  0.8298041   0.8285718   0.8305862   0.8326887\n",
      "  0.50911945 -0.8113964  -0.81055343  0.8328336   0.82953924  0.17805333\n",
      "  0.17791447  0.17558482 -0.48048803  0.5076243   0.5053034   0.50482094\n",
      "  0.18040897  0.17937788  0.1799061   0.83329403  0.8353519   0.8385056\n",
      " -0.4777488  -0.4784182  -0.81053305 -0.8102604   0.17686382  0.17832024\n",
      "  0.17925647  0.17878623  0.8321948   0.8290388  -0.15063153 -0.15075131\n",
      " -0.47801173 -0.47956342 -0.48006588 -0.47907978 -0.47877496 -0.80773103\n",
      " -0.8092977  -0.8099398  -0.1500625  -0.8090072  -0.15081258 -0.15093896\n",
      " -0.4788736  -0.47987047 -0.47808883 -0.47853202 -0.47787222 -0.47818863\n",
      " -0.15063547 -0.1512799  -0.15080649 -0.15157488 -0.15135138 -0.15190558\n",
      " -0.15163459 -0.48067862 -0.47935748]\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() * scaler [-1.1329057  -1.1340879  -0.15247424  0.8308988  -0.14965835 -0.15176082\n",
      " -0.15173784 -1.1290559  -1.1306194  -1.1323326   0.5053259  -0.47694284\n",
      " -0.4776199   2.1435223   2.1463327   0.50270325  0.504127    0.5065464\n",
      "  0.1780656   0.17818199  0.1776922   1.8128796   2.4620082   2.4700983\n",
      "  0.17978846  0.17860691  0.17778818 -0.15088698 -0.1496682  -0.47803596\n",
      " -0.47847265 -0.47864795 -0.47896713 -0.8098023  -0.81029856 -0.15134294\n",
      " -0.15094681 -0.14971796 -0.8092103  -0.8084682  -0.15027104 -0.15053564\n",
      " -0.15050277 -0.80868095 -0.8100197  -0.8103086  -0.8092177  -0.47962183\n",
      " -0.47904605 -0.8082553  -0.8097852  -0.15127687 -0.14944962 -0.14948326\n",
      " -0.1506364  -0.48061374 -0.4791101   0.1767852   0.17765504 -0.4786923\n",
      " -0.47910172  0.5060803   1.1508847   1.1596876   0.5068464   0.50483507\n",
      "  0.83299696 -0.8106435  -0.8100286   0.83134824  0.83126074  0.17861882\n",
      " -0.80940753 -0.8096455  -0.8108241  -0.8105348   0.17963028  0.5059243\n",
      "  0.50630563  0.50792164 -0.4777733  -0.15136749 -0.14967163  0.17700525\n",
      " -0.4783274  -0.47771037 -0.47932282 -0.48010394 -0.4808719  -0.808897\n",
      " -0.809168   -1.1333477  -1.1334528  -1.134229   -1.134327   -1.1345748\n",
      " -1.1342863  -0.15032777 -1.1319101  -1.1314656  -0.15263441 -0.1519646\n",
      " -0.47942176  0.8264166   0.82742757  0.83030415  0.83237326 -0.14752781\n",
      " -0.14838275 -0.14898182 -1.1345246   0.50636154  0.5061915   0.5036226\n",
      " -0.8121515  -0.8125654  -0.8113726  -0.8093537  -0.15199345 -0.15125607\n",
      " -0.15037926 -0.14908431  0.5053815   0.5054893  -0.14983718 -0.14992283\n",
      " -0.15030035 -0.1513458  -0.15134016 -0.150666   -0.4801015  -0.47801828\n",
      " -0.47775984 -0.47776312 -0.4785722  -0.47790262 -0.4779136  -0.47758293\n",
      " -1.1323907   0.5051203   0.5066406   0.5065262  -0.47979107 -0.47979698\n",
      " -0.48037252 -0.48026556 -0.48103258 -0.47963095 -0.479609   -0.478497\n",
      " -0.47965923 -1.1315696  -1.1362191  -0.8108728  -0.8103312  -0.8108186\n",
      " -0.80942273 -0.809189   -0.8059746  -0.80476665 -0.8047041  -0.80883217\n",
      " -0.80956113 -0.4766285  -0.47525507 -0.4755894  -0.47641978 -0.4799574\n",
      " -0.8106485  -0.81033796  0.17867082 -0.15253301 -0.8085148  -0.8081144\n",
      " -0.80799115 -0.80891615 -0.81129485 -0.81144446 -0.8110713  -0.812154\n",
      " -0.8121172  -0.81130254 -0.8057138  -0.8051247  -0.8027191  -0.80320597\n",
      " -0.8005087  -0.8083289  -0.809025   -1.134118   -1.1354814  -1.1361738\n",
      " -0.14950608 -0.15028407 -0.47885576 -0.47957474 -0.47997993 -0.14901704\n",
      " -0.15054987 -0.8101618  -0.81088    -0.47923744 -0.47939992 -0.4785603\n",
      " -0.8094279  -0.47835752 -0.477986   -0.47850105 -0.47914234 -0.47943723\n",
      " -0.47993034 -0.4797278  -1.1318427  -0.47906345 -0.47872937  0.18150866\n",
      "  0.17749894  0.17672251 -0.15200672 -0.47803167 -0.47904694 -0.4797227\n",
      " -0.47920313 -0.4795327  -0.4786335   0.1788008   0.17818427 -0.80983967\n",
      " -0.80977863 -0.15014786 -0.1513999  -0.15151887 -0.1523938  -0.15203077\n",
      " -0.8090526  -0.8105414  -0.81039447 -0.8114636  -0.47894526 -0.47852838\n",
      " -0.47770956  0.50715536  0.5081223   0.18067715 -0.4777085  -0.477927\n",
      "  1.1570871   1.1557015   1.1563805   1.1584603   1.158384    0.50750744\n",
      "  2.7976406   2.7942274   2.7900152   5.1006713   5.082222    5.05845\n",
      "  4.1135697   5.748458    5.7498374   5.7593145   3.4622805   3.4510036\n",
      "  3.4430425   2.4631698   2.4640563   1.8117706   1.8104548   1.8007585\n",
      " -0.47875652 -0.47916692 -0.4794442  -0.47943726  0.18039283  0.1793228\n",
      "  0.17860968 -0.8097632  -0.8089085  -0.80858433 -0.15146524 -0.15200616\n",
      " -0.1519105   0.50496083  0.50584805  0.5065296  -0.15135443 -1.1327534\n",
      " -1.1327091  -0.80998826 -0.8071906  -0.80724156  0.1800135  -0.15139367\n",
      " -0.15218163 -1.1344303  -1.1332802  -1.1319824  -0.4787955  -0.47886017\n",
      " -0.48006082 -0.80872357 -0.8093562  -0.8096797  -0.47965702 -1.1352414\n",
      " -1.1352537  -1.1339508  -0.15046623 -0.15018259 -0.47764823 -0.47781086\n",
      " -0.4786081  -0.47793412 -0.4784402  -1.1347265  -1.1352949  -1.1340591\n",
      " -0.14993794 -0.15018362 -0.1501926  -0.15005562 -0.15019439 -0.15123521\n",
      " -0.15302016 -1.1366122  -1.1353064  -1.1328323  -0.4786868  -0.4791589\n",
      " -0.80874765 -0.8078618  -0.4804607  -0.48131764 -0.4805658  -0.47912443\n",
      "  0.51228446  0.5103426   0.50850266  0.5067575   0.18014169  0.17858773\n",
      "  0.17819417  0.17780389  0.18019238  0.50806105  0.5061478   0.50438243\n",
      "  0.17874047  0.17742985  2.7965126   2.7894886   1.1542169   1.1565591\n",
      "  1.1558845   1.1518507   1.1531413   1.155995   -0.47896922 -0.4807279\n",
      " -0.15491062 -0.15312304 -0.1512062  -0.4788431  -0.47765994  1.1580042\n",
      "  0.5003977   0.50206125  0.50482297  0.5084181   0.5053332   0.8295542\n",
      "  0.8344173   2.1390562   2.1370664   0.50549203  1.8092024   1.8108935\n",
      "  1.8108745   0.17666714  0.17676723  0.17698734  1.4850519   1.4818596\n",
      "  1.4792968   1.4784623  -0.47935823 -0.47875994  0.17759943  0.17820087\n",
      " -0.15165688 -0.8085611  -0.8098818  -0.81058013  0.5106142   0.5100768\n",
      "  0.50954545  0.50912094 -0.80779165 -0.8073588  -0.8069757  -0.4778167\n",
      " -0.47880062 -0.47943658  0.17992543  0.17861676  0.17733747 -0.8100989\n",
      " -0.809649   -0.80967104 -0.8097291  -0.47983232 -1.1366099  -1.1372107\n",
      "  0.17781615 -0.8095304  -0.808526   -0.80943483 -0.8098351  -0.15092278\n",
      " -0.15069665  0.8327153   0.8312174   0.83186394  0.8326662  -0.15274331\n",
      " -0.15200403 -0.15087523  0.50584924  1.4853652   1.4851224   0.5061917\n",
      "  1.4821073   1.1565518   1.155966    1.1525431   0.8311303   0.8338435\n",
      " -0.14634429 -0.14487053 -0.14558841 -0.14688163 -0.14736699  0.5063136\n",
      "  0.50723773  0.83095556  2.1377294   2.4673848  -0.15253465  0.83157235\n",
      "  0.8315532   0.8299316   0.50273395  0.5022687   0.17926931  0.18173884\n",
      "  0.18294443  0.18580638  0.50702673  0.50562656 -0.80838877 -0.8085468\n",
      " -0.8073039  -0.15155856 -0.15097441 -1.1334642  -1.1344149  -1.1344438\n",
      " -1.1325111  -0.47840402 -0.47885847 -0.4785     -0.47839254 -0.8102422\n",
      " -0.8094638  -0.15109158 -0.15217946 -0.15168992  0.50384486 -0.4807324\n",
      " -0.48049328 -0.47927403 -0.15295161 -0.15128446 -0.15051568 -0.4791629\n",
      " -0.47842175 -0.47713992  0.17715584  0.17774768  0.8338565   0.8363395\n",
      "  0.8365802  -0.151357   -0.15172513  0.5042822  -1.1321338  -1.1328714\n",
      "  1.4869865   1.4851639   1.483432    0.5089314   0.50829643  1.4825386\n",
      "  1.4893366   1.8147633   1.8144163   1.1532822   1.1532303   2.8033652\n",
      "  2.806949   -0.14992796 -0.15057863  0.50628424  0.5052385   0.5052258\n",
      "  0.507067    0.5059233  -0.15145342 -0.1505508  -1.1378895  -1.1378022\n",
      " -0.48017207 -0.48111874 -0.4807229  -0.48016948 -0.47852218 -0.4782966\n",
      " -0.47874472 -0.4793644  -0.47919193 -0.47918805 -1.1344526  -1.1341946\n",
      " -1.1333404  -0.47830403 -1.1335088  -1.134758   -1.1305068  -1.1302506\n",
      " -1.1321518  -1.1353755  -0.80767596 -0.8065673  -0.8071389  -0.8070485\n",
      " -0.8064666  -0.81056726 -0.15111107  0.50596434 -0.47870886 -0.8090943\n",
      " -0.81059164 -0.81121415  0.5083856   0.50250024  1.8101712   1.8090047\n",
      "  1.8071665  -0.80917776 -0.80967885 -0.8081306  -0.47861743 -0.47896034\n",
      " -0.4810368  -0.48113316 -0.47772655 -0.47818187 -0.47921282 -0.47929472\n",
      "  0.17888504  0.18017602  0.8298041   0.8285718   0.8305862   0.8326887\n",
      "  0.50911945 -0.8113964  -0.81055343  0.8328336   0.82953924  0.17805333\n",
      "  0.17791447  0.17558482 -0.48048803  0.5076243   0.5053034   0.50482094\n",
      "  0.18040897  0.17937788  0.1799061   0.83329403  0.8353519   0.8385056\n",
      " -0.4777488  -0.4784182  -0.81053305 -0.8102604   0.17686382  0.17832024\n",
      "  0.17925647  0.17878623  0.8321948   0.8290388  -0.15063153 -0.15075131\n",
      " -0.47801173 -0.47956342 -0.48006588 -0.47907978 -0.47877496 -0.80773103\n",
      " -0.8092977  -0.8099398  -0.1500625  -0.8090072  -0.15081258 -0.15093896\n",
      " -0.4788736  -0.47987047 -0.47808883 -0.47853202 -0.47787222 -0.47818863\n",
      " -0.15063547 -0.1512799  -0.15080649 -0.15157488 -0.15135138 -0.15190558\n",
      " -0.15163459 -0.48067862 -0.47935748]\n",
      "MSE for key X is: 0.05671465302718948\n",
      "MSE for key NIR is: 0.05368164207706557\n",
      "MSE for key IR is: 0.061753343820195254\n",
      "MSE for key Sub-mm is: 0.2635991477375798\n",
      "Results saved to model_results.npz\n",
      "Figure(1000x800)\n"
     ]
    }
   ],
   "source": [
    "!python exe_sgra.py --gp_noise --modelfolder sgra_fold0_final_20250404_110307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='base.yaml', device='cuda:0', seed=1, testmissingratio=0.1, nfold=0, unconditional=False, gp_noise=False, modelfolder='sgra_fold0_final_20250404_110307', nsample=100, real_data_path='../Analysis/real_data.npz')\n",
      "{\n",
      "    \"train\": {\n",
      "        \"epochs\": 1,\n",
      "        \"batch_size\": 16,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"diffusion\": {\n",
      "        \"layers\": 8,\n",
      "        \"channels\": 128,\n",
      "        \"nheads\": 8,\n",
      "        \"diffusion_embedding_dim\": 256,\n",
      "        \"beta_start\": 0.0001,\n",
      "        \"beta_end\": 0.5,\n",
      "        \"num_steps\": 50,\n",
      "        \"schedule\": \"quad\"\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"is_unconditional\": false,\n",
      "        \"timeemb\": 128,\n",
      "        \"featureemb\": 16,\n",
      "        \"target_strategy\": \"random\",\n",
      "        \"test_missing_ratio\": 0.1\n",
      "    }\n",
      "}\n",
      "/home/gsasseville/.local/share/virtualenvs/Diffusion-Nf9kVZlp/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Loading pre-trained model from folder: ./save/sgra_fold0_final_20250404_110307/model.pth\n",
      "/home/gsasseville/Files/UDEM/Maitrise/SgrA/SgrA_Interpolation/Diffusion/exe_real.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"./save/\" + args.modelfolder + \"/model.pth\")\n",
      "Evaluating Model\n",
      "eval_mask[:, feature_idx].bool() tensor([False,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() [-0.59828347 -0.5988801  -0.5991378  -0.59771293 -0.2705016  -0.27007732\n",
      " -0.26934394 -0.26865163 -0.27032802 -0.2710573  -0.26966652 -0.2703128\n",
      " -0.27185944 -0.2722337  -0.2697125  -0.2702121   0.5654314   0.57090884\n",
      "  0.57175493 -0.6003768  -0.60144806 -0.60005844 -0.59889024 -0.5965633\n",
      " -0.59677744 -0.59877115 -0.59751534 -0.2655361  -0.2662447  -0.26574484\n",
      " -0.26565912 -0.2667447  -0.59541136 -0.5973648  -0.5969088   0.07302184\n",
      "  0.07250771  0.07177846  0.07156831 -0.26692295 -0.26806912 -0.26831868\n",
      " -0.2680159  -0.26975018 -0.59886956 -0.5995202  -0.5986046   0.4098686\n",
      "  0.41087633  0.41108134  0.41211295 -0.27283725 -0.2714869  -0.27122638\n",
      " -0.26977685 -0.2713544  -0.27371272 -0.27286708 -0.27026424 -0.27100527\n",
      " -0.26562822 -0.2633465   1.0696708  -0.26659906 -0.2675554  -0.26792455\n",
      " -0.26908362  1.08118     1.0833138   1.0827962   1.0832281   0.07376659\n",
      "  0.07445666  0.07390718  0.07368432  0.40961215  0.40997025  0.41001248\n",
      "  0.41222456 -0.59603727 -0.59553117 -0.59671396 -0.5953209  -0.5882779\n",
      " -0.58722234 -0.58883953 -0.5897784  -0.59173757  0.06587569  0.0699477\n",
      "  0.06531046  0.07403355  0.07420189  0.07416647  0.07398743 -0.2696663\n",
      " -0.2680694  -0.26934725 -0.26990807 -0.5990132  -0.59908    -0.5981183\n",
      " -0.5983152   0.4102124   0.40951723  0.40846446  0.4098471   0.07418133\n",
      "  0.07491078  0.07481386  0.0747975  -0.59191906 -0.58890325 -0.58925855\n",
      " -0.5890004  -0.5842082   0.24168254  0.09826591  0.27711055 -0.59793043\n",
      " -0.59769094 -0.5979799  -0.59771335 -0.5973388  -0.5974698  -0.5988334\n",
      " -0.59808123  0.7373983   0.7382557   0.7370284   0.7371112  -0.59836686\n",
      " -0.59762204 -0.5992422  -0.59856    -0.27028668 -0.2699327  -0.270312\n",
      " -0.27060145 -0.26993918 -0.26894102 -0.26903167 -0.2691928  -0.2675562\n",
      " -0.26884404 -0.269319   -0.26896402 -0.26997086 -0.26834616 -0.2693176\n",
      " -0.26827666 -0.26777294 -0.268432   -0.26757285 -0.26738217 -0.26969677\n",
      " -0.2694804  -0.27025098 -0.2701465   0.7402333   0.7408303   0.7397259\n",
      "  0.738321    0.40982166  0.4093503   0.4104396   0.41125965 -0.26589397\n",
      " -0.26532015 -0.2653772  -0.26604423  0.40969422  0.4060918   0.4057283\n",
      "  0.40809393  0.07336159  0.07452732  0.07205241  0.07401682  0.7330781\n",
      "  0.7356649   0.73853266  0.7381731   5.7727585   5.764143    5.739909\n",
      "  5.747437    8.79132     8.832281    8.815523    8.779498    3.7372277\n",
      "  3.74634     3.7526047   3.7603614   2.4246354   2.4277735   2.4337459\n",
      "  2.432638   -0.59603494 -0.59861857 -0.5992008  -0.6002242   0.40745553\n",
      "  0.40767455  0.40608513  0.40670633 -0.27023405 -0.2706689  -0.27029827\n",
      " -0.27120936  0.07431141  0.07559622  0.0763077   0.07698074 -0.26789495\n",
      " -0.26872143 -0.26883587 -0.26901627 -0.26595992 -0.2680205  -0.26893514\n",
      " -0.2691944  -0.27100024 -0.26965258 -0.26933956 -0.26936874  1.0867357\n",
      "  1.0873927   1.0890123   1.0884116  -0.5997631  -0.5999522  -0.59930825\n",
      " -0.5991198  -0.2698041  -0.2689565  -0.26939893 -0.26876873  0.40737516\n",
      "  0.40870184  0.4089077   0.40919217  0.40902185  0.40983975  0.41061863\n",
      "  0.4104953  -0.2706494  -0.269702   -0.26883823 -0.2690294   0.07546475\n",
      "  0.07557231  0.07533925  0.07621489 -0.2689948  -0.2688062  -0.26950195\n",
      " -0.26826465  0.07957614  0.07848934  0.07878064  0.07752098  0.07403997\n",
      "  0.07423531  0.0744047   0.07381142  0.07273801  0.07301797  0.07247961\n",
      "  0.0724306  -0.2666738  -0.26838943 -0.2685783  -0.26830053  0.07521275\n",
      "  0.07628743  0.07613195  0.07518937 -0.2687882  -0.26907247 -0.26907507\n",
      " -0.270306   -0.268845   -0.2688861  -0.2681731  -0.26804432  1.420595\n",
      "  1.416067    1.4133719   1.4110178  -0.5986817  -0.59880555 -0.5992559\n",
      " -0.5993627  -0.26854497 -0.26842678 -0.26892036 -0.26936087 -0.596511\n",
      " -0.59783727 -0.5972558  -0.5976824  -0.26761395 -0.26690143 -0.26648444\n",
      " -0.26770082 -0.59729373 -0.59761614 -0.5972294  -0.59699553  0.4058607\n",
      "  0.4025691   0.40462023  0.40532598  0.07551007  0.0749483   0.07424638\n",
      "  0.07380567  0.07127282  0.07301692  0.07413464  0.07499759  0.40545326\n",
      "  0.40686208  0.40629137  0.40744528  0.07868905  0.07813957  0.07824532\n",
      "  0.0774176   0.07608081  0.07632256  0.0754189   0.07605783  0.07625113\n",
      "  0.07490822  0.07565437  0.07452767 -0.268356   -0.26797706 -0.26727006\n",
      " -0.26736063 -0.2693876  -0.27036473 -0.26988152 -0.2696769  -0.270134\n",
      " -0.2706292  -0.27110878 -0.27052924 -0.27035093 -0.26976314 -0.2696084\n",
      " -0.26972485 -0.26830557 -0.2680297  -0.26904106 -0.26933733 -0.5998728\n",
      " -0.59885776 -0.6002395  -0.6002481  -0.2706167  -0.2704458  -0.2687472\n",
      " -0.26927778  0.40915638  0.40944865  0.4104132   0.4114541  -0.2671011\n",
      " -0.26810116 -0.26704082 -0.267783   -0.26784772 -0.26659703 -0.26715016\n",
      " -0.2681617  -0.5974033  -0.59692365 -0.5962047  -0.5971051   0.7428396\n",
      "  0.7414249   0.74088705  0.73882     0.41407457  0.41206864  0.4116767\n",
      "  0.4112358  -0.5956856  -0.596901   -0.5977055  -0.5983433   0.4090776\n",
      "  0.4088785   0.4076228   0.4074071   0.40729427  0.4092492   0.4109962\n",
      "  0.41143483  0.0747266   0.07250985  0.07429855  0.07383673  0.0737871\n",
      "  0.07368079  0.07493062  0.07538231 -0.26738098 -0.26885894 -0.2688484\n",
      " -0.26965103  0.41525     0.41523138  0.41308314  0.41352135 -0.26848036\n",
      " -0.26772124 -0.26798114 -0.26862106 -0.5948551  -0.5948944  -0.5959006\n",
      " -0.59775674  0.7408234   0.7425367   0.7441286   0.7432209   0.07118853\n",
      "  0.07218026  0.0727035   0.07443212 -0.59814805 -0.59839034 -0.59853935\n",
      " -0.5979734  -0.5973991  -0.5968303  -0.59693134 -0.5978426  -0.26851898\n",
      " -0.2686429  -0.26767334 -0.26830873 -0.26847324 -0.26872876 -0.26869082\n",
      " -0.2684456  -0.5968703  -0.59765476 -0.59772295 -0.5979701   0.07408989\n",
      "  0.07464654  0.07328279  0.07397434  0.0761264   0.0763407   0.07699263\n",
      "  0.07581314 -0.26770967 -0.26876426 -0.26884395 -0.26905015  0.07477761\n",
      "  0.07528377  0.07472984  0.07446662  0.7371506   0.7368238   0.7381296\n",
      "  0.74101716 -0.5965136  -0.59725046 -0.597134   -0.59737146  0.07516104\n",
      "  0.07487874  0.07492483  0.07482007 -0.5999297  -0.5982705  -0.5978297\n",
      " -0.5974382   0.07506189  0.07544928  0.07677384  0.0768698   1.0786786\n",
      "  1.0798935   1.0812454   1.0834409   1.0871395   1.0862454   1.0845227\n",
      "  1.0809942  -0.59960985 -0.5985539  -0.59803987 -0.5989836   0.07343461\n",
      "  0.07204852  0.07127502  0.07165149  0.07340759  0.07507655  0.07668921\n",
      "  0.07578471  0.07189135  0.07041226  0.07068913  0.07187614  0.41065344\n",
      "  0.41009945  0.40762317  0.40772453 -0.59862685 -0.59740293 -0.5976261\n",
      " -0.596361    0.409859    0.41147876  0.41394407  0.4143466  -0.5973629\n",
      " -0.5985357  -0.5989026  -0.5989     -0.2708875  -0.2704761  -0.26935044\n",
      " -0.26870862  0.07445371  0.0746941   0.07444835  0.07496364 -0.5984134\n",
      " -0.5988078  -0.59794444 -0.5976991  -0.26893646 -0.26855445 -0.26926076\n",
      " -0.26917803  0.7401442   0.74160796  0.738796    0.7388124  -0.26766866\n",
      " -0.2681945  -0.267912   -0.2670613  -0.26655588 -0.26619554 -0.26766226\n",
      " -0.26680055 -0.26634833 -0.26587254 -0.2661282  -0.26669246 -0.5976542\n",
      " -0.5980293  -0.5966759  -0.5983303  -0.26995608 -0.26908845 -0.2694754\n",
      " -0.26772842  0.07561731  0.07477973  0.07393839  0.07214177 -0.59699017\n",
      " -0.5962837  -0.5948167  -0.594358   -0.5955776  -0.5957428  -0.59610486\n",
      " -0.5965833   0.07475017  0.07506765  0.07468828  0.07434113 -0.26654682\n",
      " -0.26706934 -0.26806346 -0.26892522 -0.59915715 -0.5978121  -0.5997289\n",
      " -0.599451   -0.5986263  -0.59842914 -0.59966767 -0.59959376 -0.5980388\n",
      " -0.5984474  -0.59724045 -0.59735197 -0.26871142 -0.26897848 -0.26810396\n",
      " -0.2687446   0.07368246  0.07441772  0.07442865  0.07450195 -0.5988162\n",
      " -0.5989338  -0.5999498  -0.59875196 -0.26616222 -0.26632282 -0.26594037\n",
      " -0.26660195 -0.5987018  -0.59791476 -0.5973263  -0.5972661   0.40648162\n",
      "  0.40967855  0.40978467  0.4100525  -0.26868707 -0.2691385  -0.2696609\n",
      " -0.27085495 -0.26859933 -0.26833418 -0.26959154 -0.2685     -0.5971944\n",
      " -0.597031   -0.59698045 -0.59793997  0.4135637   0.41460332  0.41400465\n",
      "  0.41389737 -0.26912823 -0.26997477 -0.26963574 -0.2677434  -0.26545712\n",
      " -0.26510862 -0.2661777  -0.26560128 -0.2675413  -0.26661035 -0.26751626\n",
      " -0.26846057 -0.59532183 -0.59651    -0.5968051  -0.5967989  -0.5979616\n",
      " -0.59760624 -0.59681743 -0.5973526  -0.2700092  -0.27061588 -0.26996547\n",
      " -0.27016628 -0.5991996  -0.59990907 -0.59933597 -0.5981935  -0.27086985\n",
      " -0.26963988 -0.26918942 -0.27003616 -0.59957623 -0.5985716  -0.59879607\n",
      " -0.5964037  -0.26679936 -0.26748696 -0.26765823 -0.26832876 -0.59745926\n",
      " -0.5974727  -0.59767455 -0.5978584   0.07393412  0.0736416   0.07516019\n",
      "  0.07456834 -0.596167   -0.59626865 -0.5971834  -0.59748876 -0.26877758\n",
      " -0.26812738 -0.26729208 -0.26762632  0.40997207  0.41009596  0.40972623\n",
      "  0.40939015 -0.26862857 -0.2693178  -0.26943463 -0.2700264  -0.26917663\n",
      " -0.26901245 -0.26895523 -0.26836503 -0.26826653 -0.2680663  -0.2678835\n",
      " -0.26822048  0.07464223  0.07428792  0.07541376  0.07594505 -0.59686613\n",
      " -0.5977454  -0.5977478  -0.5979541  -0.26935586 -0.27014008 -0.27066287\n",
      " -0.26959866 -0.5977566  -0.5980909  -0.59713    -0.5967926  -0.5974754\n",
      " -0.5981423  -0.59946346 -0.598074   -0.2690884  -0.2681642  -0.26722935\n",
      " -0.26902586  0.07520165  0.07333522  0.07269886  0.07375122 -0.5975145\n",
      " -0.5978759  -0.5970583  -0.5977415   0.07327748  0.07189732  0.07259475\n",
      "  0.07325529 -0.26749074 -0.26720494 -0.26783344 -0.2689689   0.41369352\n",
      "  0.41443953  0.4146266   0.41362888 -0.2667611  -0.2669682  -0.26696324\n",
      " -0.26538095 -0.26731822 -0.58259463 -0.57815564 -0.5787498  -0.5779517\n",
      " -0.5802871  -0.5887627  -0.5901067  -0.59012055 -0.5916538 ]\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() * scaler [-0.59828347 -0.5988801  -0.5991378  -0.59771293 -0.2705016  -0.27007732\n",
      " -0.26934394 -0.26865163 -0.27032802 -0.2710573  -0.26966652 -0.2703128\n",
      " -0.27185944 -0.2722337  -0.2697125  -0.2702121   0.5654314   0.57090884\n",
      "  0.57175493 -0.6003768  -0.60144806 -0.60005844 -0.59889024 -0.5965633\n",
      " -0.59677744 -0.59877115 -0.59751534 -0.2655361  -0.2662447  -0.26574484\n",
      " -0.26565912 -0.2667447  -0.59541136 -0.5973648  -0.5969088   0.07302184\n",
      "  0.07250771  0.07177846  0.07156831 -0.26692295 -0.26806912 -0.26831868\n",
      " -0.2680159  -0.26975018 -0.59886956 -0.5995202  -0.5986046   0.4098686\n",
      "  0.41087633  0.41108134  0.41211295 -0.27283725 -0.2714869  -0.27122638\n",
      " -0.26977685 -0.2713544  -0.27371272 -0.27286708 -0.27026424 -0.27100527\n",
      " -0.26562822 -0.2633465   1.0696708  -0.26659906 -0.2675554  -0.26792455\n",
      " -0.26908362  1.08118     1.0833138   1.0827962   1.0832281   0.07376659\n",
      "  0.07445666  0.07390718  0.07368432  0.40961215  0.40997025  0.41001248\n",
      "  0.41222456 -0.59603727 -0.59553117 -0.59671396 -0.5953209  -0.5882779\n",
      " -0.58722234 -0.58883953 -0.5897784  -0.59173757  0.06587569  0.0699477\n",
      "  0.06531046  0.07403355  0.07420189  0.07416647  0.07398743 -0.2696663\n",
      " -0.2680694  -0.26934725 -0.26990807 -0.5990132  -0.59908    -0.5981183\n",
      " -0.5983152   0.4102124   0.40951723  0.40846446  0.4098471   0.07418133\n",
      "  0.07491078  0.07481386  0.0747975  -0.59191906 -0.58890325 -0.58925855\n",
      " -0.5890004  -0.5842082   0.24168254  0.09826591  0.27711055 -0.59793043\n",
      " -0.59769094 -0.5979799  -0.59771335 -0.5973388  -0.5974698  -0.5988334\n",
      " -0.59808123  0.7373983   0.7382557   0.7370284   0.7371112  -0.59836686\n",
      " -0.59762204 -0.5992422  -0.59856    -0.27028668 -0.2699327  -0.270312\n",
      " -0.27060145 -0.26993918 -0.26894102 -0.26903167 -0.2691928  -0.2675562\n",
      " -0.26884404 -0.269319   -0.26896402 -0.26997086 -0.26834616 -0.2693176\n",
      " -0.26827666 -0.26777294 -0.268432   -0.26757285 -0.26738217 -0.26969677\n",
      " -0.2694804  -0.27025098 -0.2701465   0.7402333   0.7408303   0.7397259\n",
      "  0.738321    0.40982166  0.4093503   0.4104396   0.41125965 -0.26589397\n",
      " -0.26532015 -0.2653772  -0.26604423  0.40969422  0.4060918   0.4057283\n",
      "  0.40809393  0.07336159  0.07452732  0.07205241  0.07401682  0.7330781\n",
      "  0.7356649   0.73853266  0.7381731   5.7727585   5.764143    5.739909\n",
      "  5.747437    8.79132     8.832281    8.815523    8.779498    3.7372277\n",
      "  3.74634     3.7526047   3.7603614   2.4246354   2.4277735   2.4337459\n",
      "  2.432638   -0.59603494 -0.59861857 -0.5992008  -0.6002242   0.40745553\n",
      "  0.40767455  0.40608513  0.40670633 -0.27023405 -0.2706689  -0.27029827\n",
      " -0.27120936  0.07431141  0.07559622  0.0763077   0.07698074 -0.26789495\n",
      " -0.26872143 -0.26883587 -0.26901627 -0.26595992 -0.2680205  -0.26893514\n",
      " -0.2691944  -0.27100024 -0.26965258 -0.26933956 -0.26936874  1.0867357\n",
      "  1.0873927   1.0890123   1.0884116  -0.5997631  -0.5999522  -0.59930825\n",
      " -0.5991198  -0.2698041  -0.2689565  -0.26939893 -0.26876873  0.40737516\n",
      "  0.40870184  0.4089077   0.40919217  0.40902185  0.40983975  0.41061863\n",
      "  0.4104953  -0.2706494  -0.269702   -0.26883823 -0.2690294   0.07546475\n",
      "  0.07557231  0.07533925  0.07621489 -0.2689948  -0.2688062  -0.26950195\n",
      " -0.26826465  0.07957614  0.07848934  0.07878064  0.07752098  0.07403997\n",
      "  0.07423531  0.0744047   0.07381142  0.07273801  0.07301797  0.07247961\n",
      "  0.0724306  -0.2666738  -0.26838943 -0.2685783  -0.26830053  0.07521275\n",
      "  0.07628743  0.07613195  0.07518937 -0.2687882  -0.26907247 -0.26907507\n",
      " -0.270306   -0.268845   -0.2688861  -0.2681731  -0.26804432  1.420595\n",
      "  1.416067    1.4133719   1.4110178  -0.5986817  -0.59880555 -0.5992559\n",
      " -0.5993627  -0.26854497 -0.26842678 -0.26892036 -0.26936087 -0.596511\n",
      " -0.59783727 -0.5972558  -0.5976824  -0.26761395 -0.26690143 -0.26648444\n",
      " -0.26770082 -0.59729373 -0.59761614 -0.5972294  -0.59699553  0.4058607\n",
      "  0.4025691   0.40462023  0.40532598  0.07551007  0.0749483   0.07424638\n",
      "  0.07380567  0.07127282  0.07301692  0.07413464  0.07499759  0.40545326\n",
      "  0.40686208  0.40629137  0.40744528  0.07868905  0.07813957  0.07824532\n",
      "  0.0774176   0.07608081  0.07632256  0.0754189   0.07605783  0.07625113\n",
      "  0.07490822  0.07565437  0.07452767 -0.268356   -0.26797706 -0.26727006\n",
      " -0.26736063 -0.2693876  -0.27036473 -0.26988152 -0.2696769  -0.270134\n",
      " -0.2706292  -0.27110878 -0.27052924 -0.27035093 -0.26976314 -0.2696084\n",
      " -0.26972485 -0.26830557 -0.2680297  -0.26904106 -0.26933733 -0.5998728\n",
      " -0.59885776 -0.6002395  -0.6002481  -0.2706167  -0.2704458  -0.2687472\n",
      " -0.26927778  0.40915638  0.40944865  0.4104132   0.4114541  -0.2671011\n",
      " -0.26810116 -0.26704082 -0.267783   -0.26784772 -0.26659703 -0.26715016\n",
      " -0.2681617  -0.5974033  -0.59692365 -0.5962047  -0.5971051   0.7428396\n",
      "  0.7414249   0.74088705  0.73882     0.41407457  0.41206864  0.4116767\n",
      "  0.4112358  -0.5956856  -0.596901   -0.5977055  -0.5983433   0.4090776\n",
      "  0.4088785   0.4076228   0.4074071   0.40729427  0.4092492   0.4109962\n",
      "  0.41143483  0.0747266   0.07250985  0.07429855  0.07383673  0.0737871\n",
      "  0.07368079  0.07493062  0.07538231 -0.26738098 -0.26885894 -0.2688484\n",
      " -0.26965103  0.41525     0.41523138  0.41308314  0.41352135 -0.26848036\n",
      " -0.26772124 -0.26798114 -0.26862106 -0.5948551  -0.5948944  -0.5959006\n",
      " -0.59775674  0.7408234   0.7425367   0.7441286   0.7432209   0.07118853\n",
      "  0.07218026  0.0727035   0.07443212 -0.59814805 -0.59839034 -0.59853935\n",
      " -0.5979734  -0.5973991  -0.5968303  -0.59693134 -0.5978426  -0.26851898\n",
      " -0.2686429  -0.26767334 -0.26830873 -0.26847324 -0.26872876 -0.26869082\n",
      " -0.2684456  -0.5968703  -0.59765476 -0.59772295 -0.5979701   0.07408989\n",
      "  0.07464654  0.07328279  0.07397434  0.0761264   0.0763407   0.07699263\n",
      "  0.07581314 -0.26770967 -0.26876426 -0.26884395 -0.26905015  0.07477761\n",
      "  0.07528377  0.07472984  0.07446662  0.7371506   0.7368238   0.7381296\n",
      "  0.74101716 -0.5965136  -0.59725046 -0.597134   -0.59737146  0.07516104\n",
      "  0.07487874  0.07492483  0.07482007 -0.5999297  -0.5982705  -0.5978297\n",
      " -0.5974382   0.07506189  0.07544928  0.07677384  0.0768698   1.0786786\n",
      "  1.0798935   1.0812454   1.0834409   1.0871395   1.0862454   1.0845227\n",
      "  1.0809942  -0.59960985 -0.5985539  -0.59803987 -0.5989836   0.07343461\n",
      "  0.07204852  0.07127502  0.07165149  0.07340759  0.07507655  0.07668921\n",
      "  0.07578471  0.07189135  0.07041226  0.07068913  0.07187614  0.41065344\n",
      "  0.41009945  0.40762317  0.40772453 -0.59862685 -0.59740293 -0.5976261\n",
      " -0.596361    0.409859    0.41147876  0.41394407  0.4143466  -0.5973629\n",
      " -0.5985357  -0.5989026  -0.5989     -0.2708875  -0.2704761  -0.26935044\n",
      " -0.26870862  0.07445371  0.0746941   0.07444835  0.07496364 -0.5984134\n",
      " -0.5988078  -0.59794444 -0.5976991  -0.26893646 -0.26855445 -0.26926076\n",
      " -0.26917803  0.7401442   0.74160796  0.738796    0.7388124  -0.26766866\n",
      " -0.2681945  -0.267912   -0.2670613  -0.26655588 -0.26619554 -0.26766226\n",
      " -0.26680055 -0.26634833 -0.26587254 -0.2661282  -0.26669246 -0.5976542\n",
      " -0.5980293  -0.5966759  -0.5983303  -0.26995608 -0.26908845 -0.2694754\n",
      " -0.26772842  0.07561731  0.07477973  0.07393839  0.07214177 -0.59699017\n",
      " -0.5962837  -0.5948167  -0.594358   -0.5955776  -0.5957428  -0.59610486\n",
      " -0.5965833   0.07475017  0.07506765  0.07468828  0.07434113 -0.26654682\n",
      " -0.26706934 -0.26806346 -0.26892522 -0.59915715 -0.5978121  -0.5997289\n",
      " -0.599451   -0.5986263  -0.59842914 -0.59966767 -0.59959376 -0.5980388\n",
      " -0.5984474  -0.59724045 -0.59735197 -0.26871142 -0.26897848 -0.26810396\n",
      " -0.2687446   0.07368246  0.07441772  0.07442865  0.07450195 -0.5988162\n",
      " -0.5989338  -0.5999498  -0.59875196 -0.26616222 -0.26632282 -0.26594037\n",
      " -0.26660195 -0.5987018  -0.59791476 -0.5973263  -0.5972661   0.40648162\n",
      "  0.40967855  0.40978467  0.4100525  -0.26868707 -0.2691385  -0.2696609\n",
      " -0.27085495 -0.26859933 -0.26833418 -0.26959154 -0.2685     -0.5971944\n",
      " -0.597031   -0.59698045 -0.59793997  0.4135637   0.41460332  0.41400465\n",
      "  0.41389737 -0.26912823 -0.26997477 -0.26963574 -0.2677434  -0.26545712\n",
      " -0.26510862 -0.2661777  -0.26560128 -0.2675413  -0.26661035 -0.26751626\n",
      " -0.26846057 -0.59532183 -0.59651    -0.5968051  -0.5967989  -0.5979616\n",
      " -0.59760624 -0.59681743 -0.5973526  -0.2700092  -0.27061588 -0.26996547\n",
      " -0.27016628 -0.5991996  -0.59990907 -0.59933597 -0.5981935  -0.27086985\n",
      " -0.26963988 -0.26918942 -0.27003616 -0.59957623 -0.5985716  -0.59879607\n",
      " -0.5964037  -0.26679936 -0.26748696 -0.26765823 -0.26832876 -0.59745926\n",
      " -0.5974727  -0.59767455 -0.5978584   0.07393412  0.0736416   0.07516019\n",
      "  0.07456834 -0.596167   -0.59626865 -0.5971834  -0.59748876 -0.26877758\n",
      " -0.26812738 -0.26729208 -0.26762632  0.40997207  0.41009596  0.40972623\n",
      "  0.40939015 -0.26862857 -0.2693178  -0.26943463 -0.2700264  -0.26917663\n",
      " -0.26901245 -0.26895523 -0.26836503 -0.26826653 -0.2680663  -0.2678835\n",
      " -0.26822048  0.07464223  0.07428792  0.07541376  0.07594505 -0.59686613\n",
      " -0.5977454  -0.5977478  -0.5979541  -0.26935586 -0.27014008 -0.27066287\n",
      " -0.26959866 -0.5977566  -0.5980909  -0.59713    -0.5967926  -0.5974754\n",
      " -0.5981423  -0.59946346 -0.598074   -0.2690884  -0.2681642  -0.26722935\n",
      " -0.26902586  0.07520165  0.07333522  0.07269886  0.07375122 -0.5975145\n",
      " -0.5978759  -0.5970583  -0.5977415   0.07327748  0.07189732  0.07259475\n",
      "  0.07325529 -0.26749074 -0.26720494 -0.26783344 -0.2689689   0.41369352\n",
      "  0.41443953  0.4146266   0.41362888 -0.2667611  -0.2669682  -0.26696324\n",
      " -0.26538095 -0.26731822 -0.58259463 -0.57815564 -0.5787498  -0.5779517\n",
      " -0.5802871  -0.5887627  -0.5901067  -0.59012055 -0.5916538 ]\n",
      "MSE for key X is: 1.209089863963454\n",
      "MSE for key NIR is: 1.0035453177787161\n",
      "MSE for key IR is: 0.12230993551250323\n",
      "MSE for key Sub-mm is: 412.28901170351105\n",
      "Results saved to real_results.npz\n",
      "Figure(1000x800)\n"
     ]
    }
   ],
   "source": [
    "!python exe_real.py --modelfolder sgra_fold0_final_20250404_110307 --real_data_path ../Analysis/real_data.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='base.yaml', device='cuda:0', seed=1, testmissingratio=0.1, nfold=0, unconditional=False, gp_noise=False, modelfolder='sgra_fold0_final_20250404_110307', nsample=100, real_data_path='../Analysis/coverage_test_data.npz')\n",
      "{\n",
      "    \"train\": {\n",
      "        \"epochs\": 1,\n",
      "        \"batch_size\": 16,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"diffusion\": {\n",
      "        \"layers\": 8,\n",
      "        \"channels\": 128,\n",
      "        \"nheads\": 8,\n",
      "        \"diffusion_embedding_dim\": 256,\n",
      "        \"beta_start\": 0.0001,\n",
      "        \"beta_end\": 0.5,\n",
      "        \"num_steps\": 50,\n",
      "        \"schedule\": \"quad\"\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"is_unconditional\": false,\n",
      "        \"timeemb\": 128,\n",
      "        \"featureemb\": 16,\n",
      "        \"target_strategy\": \"random\",\n",
      "        \"test_missing_ratio\": 0.1\n",
      "    }\n",
      "}\n",
      "/home/gsasseville/.local/share/virtualenvs/Diffusion-Nf9kVZlp/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Loading pre-trained model from folder: ./save/sgra_fold0_final_20250404_110307/model.pth\n",
      "/home/gsasseville/Files/UDEM/Maitrise/SgrA/SgrA_Interpolation/Diffusion/exe_real.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"./save/\" + args.modelfolder + \"/model.pth\")\n",
      "Evaluating Model\n",
      "eval_mask[:, feature_idx].bool() tensor([False,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() [-0.5536862  -0.5539913  -0.5538578  -0.5527028  -0.2516798  -0.25161862\n",
      " -0.2510392  -0.25080255 -0.2514299  -0.25207266 -0.25225064 -0.25509351\n",
      " -0.25641906 -0.25478917 -0.2542457  -0.2571367  -0.54668784 -0.545315\n",
      " -0.5456817  -0.54739887 -0.54779863 -0.5553872  -0.5557914  -0.5551516\n",
      " -0.5537851  -0.54877216 -0.5479696  -0.54785734 -0.54740953 -0.5459248\n",
      " -0.25010067 -0.2508861  -0.24953105 -0.24886768 -0.2514136  -0.5523024\n",
      " -0.55143    -0.5521442   0.0628997   0.06234248  0.06046604  0.06181227\n",
      " -0.24628784 -0.24684592 -0.24622795 -0.24514925 -0.2452233  -0.5547755\n",
      " -0.55436504 -0.5544638   0.37350374  0.3745898   0.37575713  0.37443182\n",
      " -0.25252396 -0.25149265 -0.25141487 -0.2505818  -0.25243884 -0.2529607\n",
      " -0.25241014 -0.25632983 -0.25113526 -0.24614011  0.89227664  0.9619124\n",
      " -0.24836923 -0.2481473  -0.25013348 -0.24996777 -0.25252536 -0.25140804\n",
      " -0.25082487 -0.25001302 -0.25070363  0.06393964  0.06430414  0.06380214\n",
      "  0.0633578   0.3722724   0.37200314  0.37347415  0.374879   -0.5500761\n",
      " -0.5521119  -0.5509086  -0.55138683 -0.26580048 -0.26592368 -0.2906509\n",
      " -0.26408783 -0.26406965  0.05142984  0.05559008  0.05102968  0.06430282\n",
      "  0.06408085  0.06487089  0.06504429 -0.2508798  -0.25088125 -0.25057518\n",
      " -0.25099087 -0.546454   -0.5469605  -0.5491014  -0.54645705 -0.546802\n",
      "  0.373057    0.37030345  0.37156245  0.37116763  0.06475617  0.06468185\n",
      "  0.06398422  0.06472278 -0.54439276 -0.5455418  -0.5469368  -0.54497254\n",
      " -0.5445661   0.20698816  0.14793192  0.26740202 -0.5522917  -0.55223656\n",
      " -0.5536433  -0.55330485 -0.55355984 -0.55335724 -0.5529463  -0.55232036\n",
      " -0.24557254 -0.24658386 -0.24584517 -0.24603848 -0.2464651  -0.5537529\n",
      " -0.5528163  -0.55426383 -0.55425394 -0.25095147 -0.2505878  -0.2515408\n",
      " -0.2518486  -0.25176653 -0.25142005 -0.25029987 -0.2506515  -0.25703132\n",
      " -0.25666624 -0.2559496  -0.25625744 -0.25657284 -0.2505234  -0.25035602\n",
      " -0.25067928 -0.24989063 -0.24933584 -0.24852476 -0.24761863 -0.24774426\n",
      " -0.25077358 -0.25124034 -0.25142455 -0.2519734   0.67567825  0.67631024\n",
      "  0.67538595  0.67348814  0.372547    0.37345135  0.37299466  0.3738369\n",
      " -0.24902041 -0.24663486 -0.24784932 -0.24704881 -0.23924617 -0.23762637\n",
      " -0.23626119 -0.23944259 -0.2417656  -0.24620499 -0.24833742 -0.2495429\n",
      " -0.24721865 -0.2454877   0.6698224   0.67229646  0.6737093   0.67511004\n",
      "  5.3034015   5.294413    5.2763033   5.2613883   8.511578    8.530442\n",
      "  8.503503    8.546781    3.4349358   3.4444916   3.4496963   3.4490023\n",
      "  2.2133725   2.2166367   2.2251546   2.228395   -0.55164003 -0.55294204\n",
      " -0.55317885 -0.55429846  0.3705593   0.37172356  0.36945954  0.36748526\n",
      " -0.25213963 -0.2516521  -0.25245076 -0.25234458  0.06258198  0.06501847\n",
      "  0.06617334  0.06796534 -0.25471935 -0.26085335 -0.25676507 -0.25637758\n",
      " -0.2552897  -0.25642642 -0.26477337 -0.26336572 -0.26374403 -0.26204467\n",
      " -0.2511462  -0.25132385 -0.2502356  -0.2503586   0.9944075   0.9958778\n",
      "  0.99804     0.99585587 -0.5550411  -0.5555681  -0.5551199  -0.5537253\n",
      " -0.25420478 -0.2547253  -0.25380814 -0.25405067 -0.2534353   0.3698074\n",
      "  0.37176785  0.3707063   0.37113208  0.37159252  0.37160283  0.37283993\n",
      "  0.37231353 -0.54832715 -0.5486582  -0.5469349  -0.5492825  -0.5475497\n",
      "  0.06468345  0.0655371   0.06593654  0.06515606 -0.24997954 -0.2504169\n",
      " -0.2503603  -0.2505982  -0.24895917 -0.24726593 -0.24810676 -0.24462576\n",
      " -0.24770568  0.06415283  0.0640118   0.06540996  0.06461111  0.06271538\n",
      "  0.06212535  0.06308225  0.06265476 -0.2469696  -0.2500832  -0.24989146\n",
      " -0.2504541   0.06427921  0.06563742  0.06666828  0.06634979 -0.24567866\n",
      " -0.24702697 -0.24785621 -0.24766526 -0.24741586 -0.25046086 -0.25012887\n",
      " -0.24938917 -0.24973658  1.3033519   1.301622    1.2967186   1.2952266\n",
      " -0.24565673 -0.24365151 -0.24519241 -0.2426012  -0.24201407 -0.25111136\n",
      " -0.2502771  -0.2506124  -0.25021508 -0.5524155  -0.55395144 -0.5527782\n",
      " -0.5518377  -0.24953999 -0.24841784 -0.24775495 -0.24838355 -0.5527578\n",
      " -0.55202746 -0.55222666 -0.55178607  0.36959276  0.3677702   0.36577946\n",
      "  0.36857545  0.06690488  0.06587234  0.06525817  0.06349224  0.0617669\n",
      "  0.06332998  0.0646388   0.06555468  0.36795214  0.3688463   0.3684765\n",
      "  0.37012714  0.06748205  0.06865526  0.06816007  0.06648365  0.06632461\n",
      "  0.06622559  0.06590176  0.06630965  0.06488549  0.06477561  0.06461253\n",
      "  0.0652075  -0.24949265 -0.24864379 -0.24838811 -0.24925223 -0.25040513\n",
      " -0.25104234 -0.25213742 -0.2504746  -0.2505195  -0.25212142 -0.25169864\n",
      " -0.2523101  -0.25019673 -0.24997813 -0.2489504  -0.24891311 -0.24968322\n",
      " -0.24963096 -0.25030977 -0.24946328 -0.55435216 -0.5546267  -0.5549659\n",
      " -0.55424374 -0.2514021  -0.25044695 -0.25089532 -0.25051036  0.370906\n",
      "  0.37257993  0.3732561   0.37278497 -0.25054526 -0.24984804 -0.25114116\n",
      " -0.250673   -0.25099966 -0.2492987  -0.2485732  -0.2485238  -0.24993941\n",
      " -0.54392946 -0.5479104  -0.54458797 -0.54519755 -0.5436396   0.6762547\n",
      "  0.6758971   0.6756386   0.67468184  0.37792686  0.37479126  0.3736617\n",
      "  0.3745754  -0.55071485 -0.55198246 -0.5526341  -0.55301034  0.37284547\n",
      "  0.37246788  0.37068188  0.3703243   0.37016365  0.37263635  0.37434173\n",
      "  0.37383488  0.06407945  0.06230984  0.06309275  0.06396193  0.06311591\n",
      "  0.06365092  0.06379299  0.06480104 -0.24924307 -0.25130475 -0.25084403\n",
      " -0.25081038  0.37710068  0.37777317  0.37615582  0.37442198 -0.248909\n",
      " -0.24881364 -0.249491   -0.24875236 -0.5505117  -0.55172455 -0.55301005\n",
      " -0.551614    0.6759936   0.6779624   0.6791306   0.6795681  -0.54582715\n",
      " -0.5475369  -0.5467679  -0.5465242  -0.5465774  -0.55365556 -0.552654\n",
      " -0.55332893 -0.5528821  -0.5369715  -0.5354293  -0.5383034  -0.53321195\n",
      " -0.54008234 -0.24957201 -0.25050944 -0.24903361 -0.24993601 -0.24976745\n",
      " -0.24991702 -0.25019857 -0.25003293 -0.55309224 -0.5530429  -0.5528416\n",
      " -0.55498254  0.06366134  0.06443839  0.06464063  0.06434653  0.06527004\n",
      "  0.06647746  0.06624192  0.06612306 -0.24822243 -0.24981421 -0.24945334\n",
      " -0.24981835 -0.5373677  -0.5326187  -0.5253231  -0.53860605 -0.5319003\n",
      "  0.6740612   0.6732082   0.6748173   0.6772285  -0.5512809  -0.5519725\n",
      " -0.55279666 -0.5533761   0.06524134  0.06482942  0.06381917  0.06479436\n",
      " -0.5536222  -0.55222523 -0.5528475  -0.5527963   0.06458106  0.06521334\n",
      "  0.06510138  0.06669983 -0.2504437  -0.2501042  -0.25104183 -0.25202423\n",
      " -0.25374302 -0.24865954 -0.24609545 -0.24510306 -0.24350299 -0.24501982\n",
      " -0.553961   -0.5526822  -0.55359983 -0.5529403   0.06406302  0.06224274\n",
      "  0.06128524  0.06258304  0.06394526  0.06555408  0.06611975  0.06671227\n",
      "  0.06173847  0.06012091  0.05975906  0.0621758   0.3722391   0.37185195\n",
      "  0.36942962  0.3706638  -0.5548398  -0.5539292  -0.5518513  -0.550969\n",
      "  0.3714447   0.3745287   0.3758537   0.37573963 -0.5529417  -0.55305266\n",
      " -0.55432457 -0.55444    -0.25212717 -0.25214443 -0.2510393  -0.251402\n",
      " -0.24189351 -0.23670995 -0.24091692 -0.23886377 -0.24172816 -0.55459774\n",
      " -0.55364215 -0.55304307 -0.5528666   0.06660246  0.06769636  0.06904099\n",
      "  0.06706075  0.06441225  0.24752428  0.25287578  0.24971384  0.23160665\n",
      "  0.2469483   0.06501656  0.06538951  0.06081539  0.06064291  0.06406733\n",
      " -0.24710928 -0.24745405 -0.24763426 -0.24912408 -0.24825807 -0.24728724\n",
      " -0.24824993 -0.24837348 -0.5523915  -0.5521893  -0.5526798  -0.5524998\n",
      " -0.24973306 -0.24902134 -0.24872811 -0.2488448   1.8457549   1.8483988\n",
      "  1.8465776   1.8451588   1.8496647  -0.5532547  -0.5511655  -0.5511068\n",
      " -0.5497875   1.3016574   1.3100035   1.3052125   1.3026596   1.2944168\n",
      "  0.0640448   0.06467588  0.06359521  0.06397917 -0.24743445 -0.24902597\n",
      " -0.25016558 -0.24973094 -0.5538848  -0.5536732  -0.55422217 -0.55431557\n",
      " -0.5530571  -0.5537857  -0.55528367 -0.55450714 -0.5529936  -0.5537113\n",
      " -0.55322444 -0.552569   -0.24466148 -0.24384943 -0.24482262 -0.24323827\n",
      " -0.2423499  -0.23937288 -0.24037181 -0.24039467 -0.23716922 -0.23664232\n",
      " -0.5533701  -0.5545403  -0.5547597  -0.5534616  -0.24802485 -0.24694048\n",
      " -0.24746855 -0.2497141  -0.5530397  -0.55295634 -0.5525861  -0.5519445\n",
      " -0.53841835 -0.53757864 -0.5400666  -0.5399257  -0.5393249  -0.2498492\n",
      " -0.25057    -0.25113922 -0.2526162  -0.2502249  -0.24885355 -0.25073403\n",
      " -0.25117853 -0.552075   -0.5524642  -0.5521974  -0.5524927   0.37594488\n",
      "  0.37723327  0.37776536  0.3745994  -0.5427067  -0.5420378  -0.5424793\n",
      " -0.54304236 -0.54194367 -0.24759774 -0.24638684 -0.24667792 -0.24696702\n",
      " -0.24847326 -0.24872848 -0.24912372 -0.24821672 -0.55092406 -0.55088013\n",
      " -0.5518745  -0.5524792  -0.5533107  -0.55337423 -0.5527035  -0.5525678\n",
      " -0.25112125 -0.25173536 -0.25158522 -0.25083518 -0.55324656 -0.55390054\n",
      " -0.5549878  -0.554735   -0.25519615 -0.2521582  -0.2538341  -0.25224805\n",
      " -0.25543737 -0.554693   -0.55307084 -0.552734   -0.55278164 -0.25475097\n",
      " -0.25444078 -0.25280356 -0.2538438  -0.25323886 -0.5537217  -0.55248505\n",
      " -0.55309695 -0.55321854  0.06330673  0.06393792  0.06467837  0.06546766\n",
      " -0.5514887  -0.55146813 -0.5529342  -0.5539573  -0.24941635 -0.24948551\n",
      " -0.24864922 -0.24933457  0.37259465  0.37311313  0.3716596   0.37173527\n",
      "  0.06550199  0.06795308  0.06551026  0.06760524  0.06671917 -0.25024492\n",
      " -0.2503255  -0.25016376 -0.24953742 -0.24960975 -0.24895667 -0.24912633\n",
      " -0.25039065  0.06398649  0.06576935  0.06623548  0.06669179  0.37026054\n",
      "  0.36781654  0.3717378   0.3743045   0.37067935 -0.2509309  -0.25160018\n",
      " -0.2514813  -0.25084317 -0.5534288  -0.55328953 -0.5527749  -0.5516884\n",
      " -0.55291265 -0.552874   -0.5539889  -0.5537435  -0.24968635 -0.24928673\n",
      " -0.24919263 -0.25020322  0.06461258  0.0637054   0.06310481  0.06375379\n",
      " -0.5543274  -0.55342126 -0.5536615  -0.55254745 -0.25049552 -0.25075486\n",
      " -0.24959001 -0.25269496 -0.2505852  -0.24919829 -0.24934493 -0.25090927\n",
      " -0.24996945  0.37539315  0.37642786  0.37648472  0.37769577 -0.2501233\n",
      " -0.24813214 -0.24807586 -0.24868752 -0.24904267 -0.24858205 -0.2504403\n",
      " -0.2483469  -0.24935763 -0.24906927 -0.25537857 -0.25278035 -0.25493544\n",
      " -0.25513098]\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() * scaler [-0.5536862  -0.5539913  -0.5538578  -0.5527028  -0.2516798  -0.25161862\n",
      " -0.2510392  -0.25080255 -0.2514299  -0.25207266 -0.25225064 -0.25509351\n",
      " -0.25641906 -0.25478917 -0.2542457  -0.2571367  -0.54668784 -0.545315\n",
      " -0.5456817  -0.54739887 -0.54779863 -0.5553872  -0.5557914  -0.5551516\n",
      " -0.5537851  -0.54877216 -0.5479696  -0.54785734 -0.54740953 -0.5459248\n",
      " -0.25010067 -0.2508861  -0.24953105 -0.24886768 -0.2514136  -0.5523024\n",
      " -0.55143    -0.5521442   0.0628997   0.06234248  0.06046604  0.06181227\n",
      " -0.24628784 -0.24684592 -0.24622795 -0.24514925 -0.2452233  -0.5547755\n",
      " -0.55436504 -0.5544638   0.37350374  0.3745898   0.37575713  0.37443182\n",
      " -0.25252396 -0.25149265 -0.25141487 -0.2505818  -0.25243884 -0.2529607\n",
      " -0.25241014 -0.25632983 -0.25113526 -0.24614011  0.89227664  0.9619124\n",
      " -0.24836923 -0.2481473  -0.25013348 -0.24996777 -0.25252536 -0.25140804\n",
      " -0.25082487 -0.25001302 -0.25070363  0.06393964  0.06430414  0.06380214\n",
      "  0.0633578   0.3722724   0.37200314  0.37347415  0.374879   -0.5500761\n",
      " -0.5521119  -0.5509086  -0.55138683 -0.26580048 -0.26592368 -0.2906509\n",
      " -0.26408783 -0.26406965  0.05142984  0.05559008  0.05102968  0.06430282\n",
      "  0.06408085  0.06487089  0.06504429 -0.2508798  -0.25088125 -0.25057518\n",
      " -0.25099087 -0.546454   -0.5469605  -0.5491014  -0.54645705 -0.546802\n",
      "  0.373057    0.37030345  0.37156245  0.37116763  0.06475617  0.06468185\n",
      "  0.06398422  0.06472278 -0.54439276 -0.5455418  -0.5469368  -0.54497254\n",
      " -0.5445661   0.20698816  0.14793192  0.26740202 -0.5522917  -0.55223656\n",
      " -0.5536433  -0.55330485 -0.55355984 -0.55335724 -0.5529463  -0.55232036\n",
      " -0.24557254 -0.24658386 -0.24584517 -0.24603848 -0.2464651  -0.5537529\n",
      " -0.5528163  -0.55426383 -0.55425394 -0.25095147 -0.2505878  -0.2515408\n",
      " -0.2518486  -0.25176653 -0.25142005 -0.25029987 -0.2506515  -0.25703132\n",
      " -0.25666624 -0.2559496  -0.25625744 -0.25657284 -0.2505234  -0.25035602\n",
      " -0.25067928 -0.24989063 -0.24933584 -0.24852476 -0.24761863 -0.24774426\n",
      " -0.25077358 -0.25124034 -0.25142455 -0.2519734   0.67567825  0.67631024\n",
      "  0.67538595  0.67348814  0.372547    0.37345135  0.37299466  0.3738369\n",
      " -0.24902041 -0.24663486 -0.24784932 -0.24704881 -0.23924617 -0.23762637\n",
      " -0.23626119 -0.23944259 -0.2417656  -0.24620499 -0.24833742 -0.2495429\n",
      " -0.24721865 -0.2454877   0.6698224   0.67229646  0.6737093   0.67511004\n",
      "  5.3034015   5.294413    5.2763033   5.2613883   8.511578    8.530442\n",
      "  8.503503    8.546781    3.4349358   3.4444916   3.4496963   3.4490023\n",
      "  2.2133725   2.2166367   2.2251546   2.228395   -0.55164003 -0.55294204\n",
      " -0.55317885 -0.55429846  0.3705593   0.37172356  0.36945954  0.36748526\n",
      " -0.25213963 -0.2516521  -0.25245076 -0.25234458  0.06258198  0.06501847\n",
      "  0.06617334  0.06796534 -0.25471935 -0.26085335 -0.25676507 -0.25637758\n",
      " -0.2552897  -0.25642642 -0.26477337 -0.26336572 -0.26374403 -0.26204467\n",
      " -0.2511462  -0.25132385 -0.2502356  -0.2503586   0.9944075   0.9958778\n",
      "  0.99804     0.99585587 -0.5550411  -0.5555681  -0.5551199  -0.5537253\n",
      " -0.25420478 -0.2547253  -0.25380814 -0.25405067 -0.2534353   0.3698074\n",
      "  0.37176785  0.3707063   0.37113208  0.37159252  0.37160283  0.37283993\n",
      "  0.37231353 -0.54832715 -0.5486582  -0.5469349  -0.5492825  -0.5475497\n",
      "  0.06468345  0.0655371   0.06593654  0.06515606 -0.24997954 -0.2504169\n",
      " -0.2503603  -0.2505982  -0.24895917 -0.24726593 -0.24810676 -0.24462576\n",
      " -0.24770568  0.06415283  0.0640118   0.06540996  0.06461111  0.06271538\n",
      "  0.06212535  0.06308225  0.06265476 -0.2469696  -0.2500832  -0.24989146\n",
      " -0.2504541   0.06427921  0.06563742  0.06666828  0.06634979 -0.24567866\n",
      " -0.24702697 -0.24785621 -0.24766526 -0.24741586 -0.25046086 -0.25012887\n",
      " -0.24938917 -0.24973658  1.3033519   1.301622    1.2967186   1.2952266\n",
      " -0.24565673 -0.24365151 -0.24519241 -0.2426012  -0.24201407 -0.25111136\n",
      " -0.2502771  -0.2506124  -0.25021508 -0.5524155  -0.55395144 -0.5527782\n",
      " -0.5518377  -0.24953999 -0.24841784 -0.24775495 -0.24838355 -0.5527578\n",
      " -0.55202746 -0.55222666 -0.55178607  0.36959276  0.3677702   0.36577946\n",
      "  0.36857545  0.06690488  0.06587234  0.06525817  0.06349224  0.0617669\n",
      "  0.06332998  0.0646388   0.06555468  0.36795214  0.3688463   0.3684765\n",
      "  0.37012714  0.06748205  0.06865526  0.06816007  0.06648365  0.06632461\n",
      "  0.06622559  0.06590176  0.06630965  0.06488549  0.06477561  0.06461253\n",
      "  0.0652075  -0.24949265 -0.24864379 -0.24838811 -0.24925223 -0.25040513\n",
      " -0.25104234 -0.25213742 -0.2504746  -0.2505195  -0.25212142 -0.25169864\n",
      " -0.2523101  -0.25019673 -0.24997813 -0.2489504  -0.24891311 -0.24968322\n",
      " -0.24963096 -0.25030977 -0.24946328 -0.55435216 -0.5546267  -0.5549659\n",
      " -0.55424374 -0.2514021  -0.25044695 -0.25089532 -0.25051036  0.370906\n",
      "  0.37257993  0.3732561   0.37278497 -0.25054526 -0.24984804 -0.25114116\n",
      " -0.250673   -0.25099966 -0.2492987  -0.2485732  -0.2485238  -0.24993941\n",
      " -0.54392946 -0.5479104  -0.54458797 -0.54519755 -0.5436396   0.6762547\n",
      "  0.6758971   0.6756386   0.67468184  0.37792686  0.37479126  0.3736617\n",
      "  0.3745754  -0.55071485 -0.55198246 -0.5526341  -0.55301034  0.37284547\n",
      "  0.37246788  0.37068188  0.3703243   0.37016365  0.37263635  0.37434173\n",
      "  0.37383488  0.06407945  0.06230984  0.06309275  0.06396193  0.06311591\n",
      "  0.06365092  0.06379299  0.06480104 -0.24924307 -0.25130475 -0.25084403\n",
      " -0.25081038  0.37710068  0.37777317  0.37615582  0.37442198 -0.248909\n",
      " -0.24881364 -0.249491   -0.24875236 -0.5505117  -0.55172455 -0.55301005\n",
      " -0.551614    0.6759936   0.6779624   0.6791306   0.6795681  -0.54582715\n",
      " -0.5475369  -0.5467679  -0.5465242  -0.5465774  -0.55365556 -0.552654\n",
      " -0.55332893 -0.5528821  -0.5369715  -0.5354293  -0.5383034  -0.53321195\n",
      " -0.54008234 -0.24957201 -0.25050944 -0.24903361 -0.24993601 -0.24976745\n",
      " -0.24991702 -0.25019857 -0.25003293 -0.55309224 -0.5530429  -0.5528416\n",
      " -0.55498254  0.06366134  0.06443839  0.06464063  0.06434653  0.06527004\n",
      "  0.06647746  0.06624192  0.06612306 -0.24822243 -0.24981421 -0.24945334\n",
      " -0.24981835 -0.5373677  -0.5326187  -0.5253231  -0.53860605 -0.5319003\n",
      "  0.6740612   0.6732082   0.6748173   0.6772285  -0.5512809  -0.5519725\n",
      " -0.55279666 -0.5533761   0.06524134  0.06482942  0.06381917  0.06479436\n",
      " -0.5536222  -0.55222523 -0.5528475  -0.5527963   0.06458106  0.06521334\n",
      "  0.06510138  0.06669983 -0.2504437  -0.2501042  -0.25104183 -0.25202423\n",
      " -0.25374302 -0.24865954 -0.24609545 -0.24510306 -0.24350299 -0.24501982\n",
      " -0.553961   -0.5526822  -0.55359983 -0.5529403   0.06406302  0.06224274\n",
      "  0.06128524  0.06258304  0.06394526  0.06555408  0.06611975  0.06671227\n",
      "  0.06173847  0.06012091  0.05975906  0.0621758   0.3722391   0.37185195\n",
      "  0.36942962  0.3706638  -0.5548398  -0.5539292  -0.5518513  -0.550969\n",
      "  0.3714447   0.3745287   0.3758537   0.37573963 -0.5529417  -0.55305266\n",
      " -0.55432457 -0.55444    -0.25212717 -0.25214443 -0.2510393  -0.251402\n",
      " -0.24189351 -0.23670995 -0.24091692 -0.23886377 -0.24172816 -0.55459774\n",
      " -0.55364215 -0.55304307 -0.5528666   0.06660246  0.06769636  0.06904099\n",
      "  0.06706075  0.06441225  0.24752428  0.25287578  0.24971384  0.23160665\n",
      "  0.2469483   0.06501656  0.06538951  0.06081539  0.06064291  0.06406733\n",
      " -0.24710928 -0.24745405 -0.24763426 -0.24912408 -0.24825807 -0.24728724\n",
      " -0.24824993 -0.24837348 -0.5523915  -0.5521893  -0.5526798  -0.5524998\n",
      " -0.24973306 -0.24902134 -0.24872811 -0.2488448   1.8457549   1.8483988\n",
      "  1.8465776   1.8451588   1.8496647  -0.5532547  -0.5511655  -0.5511068\n",
      " -0.5497875   1.3016574   1.3100035   1.3052125   1.3026596   1.2944168\n",
      "  0.0640448   0.06467588  0.06359521  0.06397917 -0.24743445 -0.24902597\n",
      " -0.25016558 -0.24973094 -0.5538848  -0.5536732  -0.55422217 -0.55431557\n",
      " -0.5530571  -0.5537857  -0.55528367 -0.55450714 -0.5529936  -0.5537113\n",
      " -0.55322444 -0.552569   -0.24466148 -0.24384943 -0.24482262 -0.24323827\n",
      " -0.2423499  -0.23937288 -0.24037181 -0.24039467 -0.23716922 -0.23664232\n",
      " -0.5533701  -0.5545403  -0.5547597  -0.5534616  -0.24802485 -0.24694048\n",
      " -0.24746855 -0.2497141  -0.5530397  -0.55295634 -0.5525861  -0.5519445\n",
      " -0.53841835 -0.53757864 -0.5400666  -0.5399257  -0.5393249  -0.2498492\n",
      " -0.25057    -0.25113922 -0.2526162  -0.2502249  -0.24885355 -0.25073403\n",
      " -0.25117853 -0.552075   -0.5524642  -0.5521974  -0.5524927   0.37594488\n",
      "  0.37723327  0.37776536  0.3745994  -0.5427067  -0.5420378  -0.5424793\n",
      " -0.54304236 -0.54194367 -0.24759774 -0.24638684 -0.24667792 -0.24696702\n",
      " -0.24847326 -0.24872848 -0.24912372 -0.24821672 -0.55092406 -0.55088013\n",
      " -0.5518745  -0.5524792  -0.5533107  -0.55337423 -0.5527035  -0.5525678\n",
      " -0.25112125 -0.25173536 -0.25158522 -0.25083518 -0.55324656 -0.55390054\n",
      " -0.5549878  -0.554735   -0.25519615 -0.2521582  -0.2538341  -0.25224805\n",
      " -0.25543737 -0.554693   -0.55307084 -0.552734   -0.55278164 -0.25475097\n",
      " -0.25444078 -0.25280356 -0.2538438  -0.25323886 -0.5537217  -0.55248505\n",
      " -0.55309695 -0.55321854  0.06330673  0.06393792  0.06467837  0.06546766\n",
      " -0.5514887  -0.55146813 -0.5529342  -0.5539573  -0.24941635 -0.24948551\n",
      " -0.24864922 -0.24933457  0.37259465  0.37311313  0.3716596   0.37173527\n",
      "  0.06550199  0.06795308  0.06551026  0.06760524  0.06671917 -0.25024492\n",
      " -0.2503255  -0.25016376 -0.24953742 -0.24960975 -0.24895667 -0.24912633\n",
      " -0.25039065  0.06398649  0.06576935  0.06623548  0.06669179  0.37026054\n",
      "  0.36781654  0.3717378   0.3743045   0.37067935 -0.2509309  -0.25160018\n",
      " -0.2514813  -0.25084317 -0.5534288  -0.55328953 -0.5527749  -0.5516884\n",
      " -0.55291265 -0.552874   -0.5539889  -0.5537435  -0.24968635 -0.24928673\n",
      " -0.24919263 -0.25020322  0.06461258  0.0637054   0.06310481  0.06375379\n",
      " -0.5543274  -0.55342126 -0.5536615  -0.55254745 -0.25049552 -0.25075486\n",
      " -0.24959001 -0.25269496 -0.2505852  -0.24919829 -0.24934493 -0.25090927\n",
      " -0.24996945  0.37539315  0.37642786  0.37648472  0.37769577 -0.2501233\n",
      " -0.24813214 -0.24807586 -0.24868752 -0.24904267 -0.24858205 -0.2504403\n",
      " -0.2483469  -0.24935763 -0.24906927 -0.25537857 -0.25278035 -0.25493544\n",
      " -0.25513098]\n",
      "MSE for key X is: 1.0210202519314504\n",
      "MSE for key NIR is: 1.094194600510495\n",
      "MSE for key IR is: 0.025911697974571817\n",
      "MSE for key Sub-mm is: 390.5920869430693\n",
      "Results saved to coverage_test.npz\n",
      "Figure(1000x800)\n"
     ]
    }
   ],
   "source": [
    "!python exe_real.py --modelfolder sgra_fold0_final_20250404_110307 --real_data_path ../Analysis/coverage_test_data.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='base.yaml', device='cuda:0', seed=1, testmissingratio=0.1, nfold=0, unconditional=False, gp_noise=False, modelfolder='sgra_fold0_final_20250404_110307', nsample=100, real_data_path='../Analysis/coverage_test_data.npz')\n",
      "{\n",
      "    \"train\": {\n",
      "        \"epochs\": 1,\n",
      "        \"batch_size\": 16,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"diffusion\": {\n",
      "        \"layers\": 8,\n",
      "        \"channels\": 128,\n",
      "        \"nheads\": 8,\n",
      "        \"diffusion_embedding_dim\": 256,\n",
      "        \"beta_start\": 0.0001,\n",
      "        \"beta_end\": 0.5,\n",
      "        \"num_steps\": 50,\n",
      "        \"schedule\": \"quad\"\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"is_unconditional\": false,\n",
      "        \"timeemb\": 128,\n",
      "        \"featureemb\": 16,\n",
      "        \"target_strategy\": \"random\",\n",
      "        \"test_missing_ratio\": 0.1\n",
      "    }\n",
      "}\n",
      "/home/gsasseville/.local/share/virtualenvs/Diffusion-Nf9kVZlp/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Loading pre-trained model from folder: ./save/sgra_fold0_final_20250404_110307/model.pth\n",
      "/home/gsasseville/Files/UDEM/Maitrise/SgrA/SgrA_Interpolation/Diffusion/exe_real.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"./save/\" + args.modelfolder + \"/model.pth\")\n",
      "Evaluating Model\n",
      "eval_mask[:, feature_idx].bool() tensor([False,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "        False,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() [-0.5981506  -0.59826666 -0.59647745 -0.596327   -0.27053574 -0.26898438\n",
      " -0.2689618  -0.2687146  -0.2690896  -0.26986817 -0.26962835 -0.27134463\n",
      " -0.26859242 -0.2705449  -0.26924303 -0.26908937 -0.5111457  -0.5108461\n",
      " -0.5084268  -0.5128332  -0.5123776  -0.5990067  -0.60056305 -0.59934795\n",
      " -0.598835   -0.59260774 -0.5912241  -0.5908662  -0.5903143  -0.5934386\n",
      " -0.26789135 -0.26706597 -0.26835585 -0.26882762 -0.26802287 -0.59635514\n",
      " -0.5957906  -0.5963981   0.07382748  0.07371702  0.07253519  0.07192372\n",
      " -0.26057562 -0.2658865  -0.26444536 -0.26433837 -0.26352966 -0.59824604\n",
      " -0.598217   -0.5974354   0.41186187  0.41366616  0.41337055  0.41389903\n",
      " -0.27090064 -0.2711129  -0.26854777 -0.2685869  -0.26762217 -0.26878595\n",
      " -0.26959696 -0.26762456 -0.26673615 -0.26225823 -0.25902948  1.0684861\n",
      " -0.26563814 -0.26624864 -0.2672853  -0.26769817 -0.27962562 -0.278467\n",
      " -0.27396974 -0.2772912  -0.27624524  0.07457947  0.07553647  0.07460535\n",
      "  0.07472943  0.40952155  0.41090897  0.41195866  0.41326675 -0.5948065\n",
      " -0.59481174 -0.5957407  -0.5965262  -0.58455753 -0.58566576 -0.5920392\n",
      " -0.5873824  -0.5903903   0.06887334  0.07065347  0.06758567  0.07496082\n",
      "  0.07482476  0.07598869  0.07527441 -0.2692391  -0.26789546 -0.26842588\n",
      " -0.26814467 -0.27270195 -0.27553907 -0.2736786  -0.27256185 -0.26887953\n",
      "  0.41139066  0.40954912  0.41011894  0.41064507  0.0761251   0.07465067\n",
      "  0.0754308   0.07604655 -0.5894636  -0.58838886 -0.58801115 -0.5887149\n",
      " -0.5860341   0.2552503   0.14065331  0.2824135  -0.59706926 -0.59761804\n",
      " -0.5966658  -0.5972454  -0.596697   -0.5971779  -0.59655046 -0.59625703\n",
      " -0.2613487  -0.26069346 -0.26180455 -0.26076066 -0.26269963 -0.59729373\n",
      " -0.597075   -0.59723854 -0.59811443 -0.2696513  -0.26995894 -0.26973933\n",
      " -0.27032483 -0.2692444  -0.2688729  -0.2676139  -0.26740283 -0.27433518\n",
      " -0.27232665 -0.27386037 -0.27449363 -0.27229932 -0.2683473  -0.26915973\n",
      " -0.26772353 -0.26726705 -0.2657677  -0.26554245 -0.2658868  -0.26542974\n",
      " -0.26808587 -0.2682692  -0.26893246 -0.26869765  0.74098384  0.7418884\n",
      "  0.7412151   0.73932755  0.40972856  0.41115996  0.41292807  0.41161487\n",
      " -0.26608688 -0.2646453  -0.2643097  -0.26509374 -0.26463428 -0.264512\n",
      " -0.26303518 -0.26425081 -0.26360327 -0.2590545  -0.2611442  -0.26510587\n",
      " -0.26205152 -0.2599236   0.73484457  0.7377385   0.7384508   0.7421167\n",
      "  5.720747    5.71686     5.7082224   5.724999    8.730863    8.758191\n",
      "  8.838634    8.836909    3.746441    3.7555113   3.764217    3.767031\n",
      "  2.4236238   2.426995    2.430434    2.4318032  -0.5959227  -0.59738594\n",
      " -0.5985583  -0.59864455  0.4090776   0.40828583  0.4085069   0.40745994\n",
      " -0.26858938 -0.2693942  -0.26992366 -0.27070266  0.07512684  0.07658675\n",
      "  0.07772531  0.07876846 -0.26865524 -0.26757056 -0.26731113 -0.26817092\n",
      " -0.26926202 -0.58389926 -0.5819105  -0.5849431  -0.5890134  -0.5891953\n",
      " -0.26975614 -0.26898527 -0.26915362 -0.26821616  1.0894343   1.089665\n",
      "  1.0897592   1.089691   -0.59902704 -0.59891355 -0.5984073  -0.59744793\n",
      " -0.58955836 -0.5921969  -0.5930279  -0.5938028  -0.59216994  0.40854198\n",
      "  0.40904245  0.4095707   0.41021118  0.41001028  0.41110486  0.41124234\n",
      "  0.4112642  -0.5864468  -0.584808   -0.58491427 -0.58701724 -0.5846914\n",
      "  0.07540242  0.07664333  0.07720594  0.0768137  -0.268309   -0.26794547\n",
      " -0.2673508  -0.26684204 -0.26333392 -0.26512152 -0.26528925 -0.2649892\n",
      " -0.26301548  0.07670496  0.07513689  0.07612401  0.07579323  0.0739243\n",
      "  0.07375709  0.07348563  0.07507026 -0.2666798  -0.2683145  -0.26777533\n",
      " -0.26796886  0.07620595  0.0775709   0.07820252  0.07735914 -0.26174647\n",
      " -0.26286304 -0.26406556 -0.26453477 -0.2644563  -0.26773638 -0.26715034\n",
      " -0.26711568 -0.26801053  1.425805    1.4221756   1.4173105   1.4155641\n",
      "  0.07861357  0.078728    0.08004307  0.0808679   0.08209477 -0.2669079\n",
      " -0.26772818 -0.2683401  -0.26822534 -0.5973867  -0.59737694 -0.59740525\n",
      " -0.5972529  -0.26765457 -0.26633433 -0.26584578 -0.26653817 -0.59519875\n",
      " -0.5958809  -0.5970876  -0.59558284  0.40909493  0.4061656   0.4056861\n",
      "  0.4071192   0.0774149   0.07712533  0.07579139  0.07420857  0.07215704\n",
      "  0.07382815  0.07516865  0.07561285  0.40634984  0.4064171   0.40750518\n",
      "  0.40858203  0.07945526  0.08024324  0.07979391  0.0772742   0.07772792\n",
      "  0.07774679  0.07723914  0.0763723   0.07626791  0.07597309  0.07557958\n",
      "  0.07576002 -0.26729077 -0.26668283 -0.2665874  -0.2664323  -0.26827106\n",
      " -0.2686938  -0.26897758 -0.26933587 -0.26944846 -0.2688851  -0.2702531\n",
      " -0.26915896 -0.2684573  -0.26920232 -0.26794556 -0.2675733  -0.26748207\n",
      " -0.26741627 -0.26662567 -0.26761773 -0.5983146  -0.597939   -0.5987677\n",
      " -0.59960014 -0.2690153  -0.26937166 -0.2686466  -0.2678942   0.40995046\n",
      "  0.4107048   0.41114122  0.4116695  -0.26645306 -0.26989517 -0.27054593\n",
      " -0.27009258 -0.27046376 -0.2658646  -0.26636294 -0.26742828 -0.2672481\n",
      " -0.27824423 -0.27747855 -0.2773555  -0.27989852 -0.27338997  0.74385685\n",
      "  0.7427184   0.74097896  0.7396625   0.41526672  0.41262174  0.41260105\n",
      "  0.41248554 -0.5960313  -0.5958041  -0.59635055 -0.59718513  0.41047382\n",
      "  0.41045278  0.41036034  0.4083187   0.4075661   0.41042528  0.4117939\n",
      "  0.41324693  0.0751529   0.07445273  0.07500815  0.07544369  0.07400845\n",
      "  0.07483452  0.07563679  0.07561897 -0.26792425 -0.268182   -0.26810157\n",
      " -0.26907176  0.41646063  0.41540265  0.41473588  0.41303232 -0.26662174\n",
      " -0.2667727  -0.26740474 -0.26765278 -0.59411305 -0.5953061  -0.596282\n",
      " -0.59658706  0.7421749   0.7432858   0.7446332   0.7441992  -0.59543765\n",
      " -0.59567386 -0.5947118  -0.59379756 -0.5947393  -0.59654254 -0.59776485\n",
      " -0.596512   -0.59814674 -0.5897252  -0.5895817  -0.591209   -0.591169\n",
      " -0.590335   -0.26725945 -0.268417   -0.2676778  -0.26697367 -0.26771796\n",
      " -0.2667593  -0.26627433 -0.26688355 -0.59608287 -0.5975574  -0.59710747\n",
      " -0.59741515  0.07540852  0.074839    0.07616245  0.07571248  0.07617641\n",
      "  0.07679174  0.07753935  0.07706439 -0.26711366 -0.2679014  -0.26850805\n",
      " -0.26719806 -0.5906802  -0.58971715 -0.5884324  -0.5855012  -0.59033453\n",
      "  0.7374118   0.73786396  0.7400956   0.74219096 -0.59644365 -0.5956358\n",
      " -0.59699243 -0.59742135  0.07677678  0.07608116  0.07524445  0.07604122\n",
      " -0.59804565 -0.5970625  -0.5971885  -0.5970682   0.07575842  0.0757283\n",
      "  0.07729048  0.0777045  -0.26817244 -0.26770929 -0.2694624  -0.26960525\n",
      " -0.2701967  -0.26601642 -0.26502123 -0.2646969  -0.26624057 -0.26356813\n",
      " -0.59832495 -0.5980145  -0.5976998  -0.5977488   0.07533011  0.07344541\n",
      "  0.07291494  0.07245832  0.07547967  0.07681117  0.07837453  0.07797376\n",
      "  0.07356697  0.07221718  0.07223888  0.07327818  0.41164398  0.41072366\n",
      "  0.4100307   0.40839538 -0.59826726 -0.59742653 -0.5967887  -0.5956056\n",
      "  0.41073427  0.411976    0.41340137  0.41531637 -0.59772724 -0.5980664\n",
      " -0.59817845 -0.5978671  -0.2701039  -0.26999107 -0.26895934 -0.26910523\n",
      "  0.07005149  0.07306483  0.07384605  0.07171494  0.0685195  -0.59852904\n",
      " -0.5988248  -0.5966871  -0.598723    0.07670149  0.07904039  0.07836188\n",
      "  0.07816667  0.07615038  0.07499524  0.07145095  0.07188492  0.07511954\n",
      "  0.07558976  0.07967087  0.07933912  0.07889238  0.08044305  0.08014399\n",
      " -0.26534188 -0.26554313 -0.26581103 -0.26551312 -0.266205   -0.26682758\n",
      " -0.26526478 -0.26540262 -0.59553206 -0.5958324  -0.59586513 -0.59692067\n",
      " -0.26720446 -0.26756763 -0.2668175  -0.26626518  1.7283638   1.7151835\n",
      "  1.7209729   1.7278802   1.7181151  -0.59698087 -0.59517616 -0.5937193\n",
      " -0.59322816  1.4155563   1.406097    1.4255494   1.3949353   1.4108704\n",
      "  0.07518654  0.07580668  0.07636785  0.07467438 -0.26468956 -0.26719785\n",
      " -0.2677962  -0.26844975 -0.59834176 -0.5976998  -0.59796757 -0.59825975\n",
      " -0.597224   -0.5982547  -0.59841025 -0.59929734 -0.59788096 -0.5974822\n",
      " -0.59776825 -0.597762    0.07072689  0.070715    0.0689001   0.07065462\n",
      "  0.06994729 -0.24236055 -0.25778076 -0.26168564 -0.26081482 -0.25457358\n",
      " -0.59785825 -0.59925854 -0.5987098  -0.59739673 -0.2658253  -0.26539645\n",
      " -0.26552495 -0.26636377 -0.59725225 -0.5958173  -0.5965338  -0.59565914\n",
      " -0.2760775  -0.27517787 -0.27368405 -0.27645564 -0.27541435 -0.26680744\n",
      " -0.26887098 -0.26946113 -0.26955125 -0.26776716 -0.2674306  -0.2676804\n",
      " -0.26796407 -0.595819   -0.5960203  -0.59593695 -0.5977597   0.4156586\n",
      "  0.41698694  0.41632655  0.4150748  -0.59271216 -0.5917626  -0.59056234\n",
      " -0.58791435 -0.5861044  -0.26573718 -0.26438254 -0.2650887  -0.2646951\n",
      " -0.26675332 -0.26692998 -0.2663739  -0.26731414 -0.5944563  -0.5956718\n",
      " -0.59609836 -0.5968936  -0.5967734  -0.59665525 -0.5958014  -0.59756005\n",
      " -0.26868445 -0.2696669  -0.26856726 -0.26817808 -0.59769905 -0.59788215\n",
      " -0.598189   -0.59807116 -0.27173677 -0.27166042 -0.27082324 -0.27066743\n",
      " -0.2707706  -0.59892035 -0.5993385  -0.59644955 -0.5967241  -0.27020243\n",
      " -0.27359506 -0.27444088 -0.2767122  -0.27742395 -0.59700114 -0.5975069\n",
      " -0.595804   -0.59697455  0.07432596  0.07476746  0.07592978  0.07674263\n",
      " -0.5947734  -0.5964508  -0.5973172  -0.5976757  -0.26716608 -0.26685703\n",
      " -0.26686725 -0.26635042  0.4116774   0.41187534  0.41096708  0.41066915\n",
      "  0.07640453  0.07555614  0.07458258  0.0764209   0.07586656 -0.26844606\n",
      " -0.26817426 -0.2675166  -0.26689368 -0.26726362 -0.26698548 -0.2676087\n",
      " -0.26772022  0.07499132  0.07589787  0.07732855  0.0774157   0.08555979\n",
      "  0.08082429  0.08010348  0.0777562   0.07797641 -0.26912174 -0.26921374\n",
      " -0.2689154  -0.26888856 -0.59726506 -0.5968652  -0.59625083 -0.595743\n",
      " -0.596664   -0.59734136 -0.5982644  -0.5984263  -0.26812002 -0.2669538\n",
      " -0.26736426 -0.26795143  0.07548193  0.07464267  0.07414336  0.07453752\n",
      " -0.5973387  -0.5980762  -0.5971909  -0.59741974 -0.26744658 -0.26997802\n",
      " -0.26759553 -0.2673884  -0.26944482 -0.2659119  -0.26685864 -0.26740596\n",
      " -0.26696932  0.41589016  0.41561905  0.41533244  0.41526884 -0.26659176\n",
      " -0.2631779  -0.26548818 -0.26484725 -0.2639819  -0.26516423 -0.26651344\n",
      " -0.26715165 -0.26725    -0.26606756 -0.26676866 -0.2685038  -0.26946756\n",
      " -0.27058998]\n",
      "predicted_values[eval_mask[:, feature_idx].bool(), feature_idx].numpy() * scaler [-0.5981506  -0.59826666 -0.59647745 -0.596327   -0.27053574 -0.26898438\n",
      " -0.2689618  -0.2687146  -0.2690896  -0.26986817 -0.26962835 -0.27134463\n",
      " -0.26859242 -0.2705449  -0.26924303 -0.26908937 -0.5111457  -0.5108461\n",
      " -0.5084268  -0.5128332  -0.5123776  -0.5990067  -0.60056305 -0.59934795\n",
      " -0.598835   -0.59260774 -0.5912241  -0.5908662  -0.5903143  -0.5934386\n",
      " -0.26789135 -0.26706597 -0.26835585 -0.26882762 -0.26802287 -0.59635514\n",
      " -0.5957906  -0.5963981   0.07382748  0.07371702  0.07253519  0.07192372\n",
      " -0.26057562 -0.2658865  -0.26444536 -0.26433837 -0.26352966 -0.59824604\n",
      " -0.598217   -0.5974354   0.41186187  0.41366616  0.41337055  0.41389903\n",
      " -0.27090064 -0.2711129  -0.26854777 -0.2685869  -0.26762217 -0.26878595\n",
      " -0.26959696 -0.26762456 -0.26673615 -0.26225823 -0.25902948  1.0684861\n",
      " -0.26563814 -0.26624864 -0.2672853  -0.26769817 -0.27962562 -0.278467\n",
      " -0.27396974 -0.2772912  -0.27624524  0.07457947  0.07553647  0.07460535\n",
      "  0.07472943  0.40952155  0.41090897  0.41195866  0.41326675 -0.5948065\n",
      " -0.59481174 -0.5957407  -0.5965262  -0.58455753 -0.58566576 -0.5920392\n",
      " -0.5873824  -0.5903903   0.06887334  0.07065347  0.06758567  0.07496082\n",
      "  0.07482476  0.07598869  0.07527441 -0.2692391  -0.26789546 -0.26842588\n",
      " -0.26814467 -0.27270195 -0.27553907 -0.2736786  -0.27256185 -0.26887953\n",
      "  0.41139066  0.40954912  0.41011894  0.41064507  0.0761251   0.07465067\n",
      "  0.0754308   0.07604655 -0.5894636  -0.58838886 -0.58801115 -0.5887149\n",
      " -0.5860341   0.2552503   0.14065331  0.2824135  -0.59706926 -0.59761804\n",
      " -0.5966658  -0.5972454  -0.596697   -0.5971779  -0.59655046 -0.59625703\n",
      " -0.2613487  -0.26069346 -0.26180455 -0.26076066 -0.26269963 -0.59729373\n",
      " -0.597075   -0.59723854 -0.59811443 -0.2696513  -0.26995894 -0.26973933\n",
      " -0.27032483 -0.2692444  -0.2688729  -0.2676139  -0.26740283 -0.27433518\n",
      " -0.27232665 -0.27386037 -0.27449363 -0.27229932 -0.2683473  -0.26915973\n",
      " -0.26772353 -0.26726705 -0.2657677  -0.26554245 -0.2658868  -0.26542974\n",
      " -0.26808587 -0.2682692  -0.26893246 -0.26869765  0.74098384  0.7418884\n",
      "  0.7412151   0.73932755  0.40972856  0.41115996  0.41292807  0.41161487\n",
      " -0.26608688 -0.2646453  -0.2643097  -0.26509374 -0.26463428 -0.264512\n",
      " -0.26303518 -0.26425081 -0.26360327 -0.2590545  -0.2611442  -0.26510587\n",
      " -0.26205152 -0.2599236   0.73484457  0.7377385   0.7384508   0.7421167\n",
      "  5.720747    5.71686     5.7082224   5.724999    8.730863    8.758191\n",
      "  8.838634    8.836909    3.746441    3.7555113   3.764217    3.767031\n",
      "  2.4236238   2.426995    2.430434    2.4318032  -0.5959227  -0.59738594\n",
      " -0.5985583  -0.59864455  0.4090776   0.40828583  0.4085069   0.40745994\n",
      " -0.26858938 -0.2693942  -0.26992366 -0.27070266  0.07512684  0.07658675\n",
      "  0.07772531  0.07876846 -0.26865524 -0.26757056 -0.26731113 -0.26817092\n",
      " -0.26926202 -0.58389926 -0.5819105  -0.5849431  -0.5890134  -0.5891953\n",
      " -0.26975614 -0.26898527 -0.26915362 -0.26821616  1.0894343   1.089665\n",
      "  1.0897592   1.089691   -0.59902704 -0.59891355 -0.5984073  -0.59744793\n",
      " -0.58955836 -0.5921969  -0.5930279  -0.5938028  -0.59216994  0.40854198\n",
      "  0.40904245  0.4095707   0.41021118  0.41001028  0.41110486  0.41124234\n",
      "  0.4112642  -0.5864468  -0.584808   -0.58491427 -0.58701724 -0.5846914\n",
      "  0.07540242  0.07664333  0.07720594  0.0768137  -0.268309   -0.26794547\n",
      " -0.2673508  -0.26684204 -0.26333392 -0.26512152 -0.26528925 -0.2649892\n",
      " -0.26301548  0.07670496  0.07513689  0.07612401  0.07579323  0.0739243\n",
      "  0.07375709  0.07348563  0.07507026 -0.2666798  -0.2683145  -0.26777533\n",
      " -0.26796886  0.07620595  0.0775709   0.07820252  0.07735914 -0.26174647\n",
      " -0.26286304 -0.26406556 -0.26453477 -0.2644563  -0.26773638 -0.26715034\n",
      " -0.26711568 -0.26801053  1.425805    1.4221756   1.4173105   1.4155641\n",
      "  0.07861357  0.078728    0.08004307  0.0808679   0.08209477 -0.2669079\n",
      " -0.26772818 -0.2683401  -0.26822534 -0.5973867  -0.59737694 -0.59740525\n",
      " -0.5972529  -0.26765457 -0.26633433 -0.26584578 -0.26653817 -0.59519875\n",
      " -0.5958809  -0.5970876  -0.59558284  0.40909493  0.4061656   0.4056861\n",
      "  0.4071192   0.0774149   0.07712533  0.07579139  0.07420857  0.07215704\n",
      "  0.07382815  0.07516865  0.07561285  0.40634984  0.4064171   0.40750518\n",
      "  0.40858203  0.07945526  0.08024324  0.07979391  0.0772742   0.07772792\n",
      "  0.07774679  0.07723914  0.0763723   0.07626791  0.07597309  0.07557958\n",
      "  0.07576002 -0.26729077 -0.26668283 -0.2665874  -0.2664323  -0.26827106\n",
      " -0.2686938  -0.26897758 -0.26933587 -0.26944846 -0.2688851  -0.2702531\n",
      " -0.26915896 -0.2684573  -0.26920232 -0.26794556 -0.2675733  -0.26748207\n",
      " -0.26741627 -0.26662567 -0.26761773 -0.5983146  -0.597939   -0.5987677\n",
      " -0.59960014 -0.2690153  -0.26937166 -0.2686466  -0.2678942   0.40995046\n",
      "  0.4107048   0.41114122  0.4116695  -0.26645306 -0.26989517 -0.27054593\n",
      " -0.27009258 -0.27046376 -0.2658646  -0.26636294 -0.26742828 -0.2672481\n",
      " -0.27824423 -0.27747855 -0.2773555  -0.27989852 -0.27338997  0.74385685\n",
      "  0.7427184   0.74097896  0.7396625   0.41526672  0.41262174  0.41260105\n",
      "  0.41248554 -0.5960313  -0.5958041  -0.59635055 -0.59718513  0.41047382\n",
      "  0.41045278  0.41036034  0.4083187   0.4075661   0.41042528  0.4117939\n",
      "  0.41324693  0.0751529   0.07445273  0.07500815  0.07544369  0.07400845\n",
      "  0.07483452  0.07563679  0.07561897 -0.26792425 -0.268182   -0.26810157\n",
      " -0.26907176  0.41646063  0.41540265  0.41473588  0.41303232 -0.26662174\n",
      " -0.2667727  -0.26740474 -0.26765278 -0.59411305 -0.5953061  -0.596282\n",
      " -0.59658706  0.7421749   0.7432858   0.7446332   0.7441992  -0.59543765\n",
      " -0.59567386 -0.5947118  -0.59379756 -0.5947393  -0.59654254 -0.59776485\n",
      " -0.596512   -0.59814674 -0.5897252  -0.5895817  -0.591209   -0.591169\n",
      " -0.590335   -0.26725945 -0.268417   -0.2676778  -0.26697367 -0.26771796\n",
      " -0.2667593  -0.26627433 -0.26688355 -0.59608287 -0.5975574  -0.59710747\n",
      " -0.59741515  0.07540852  0.074839    0.07616245  0.07571248  0.07617641\n",
      "  0.07679174  0.07753935  0.07706439 -0.26711366 -0.2679014  -0.26850805\n",
      " -0.26719806 -0.5906802  -0.58971715 -0.5884324  -0.5855012  -0.59033453\n",
      "  0.7374118   0.73786396  0.7400956   0.74219096 -0.59644365 -0.5956358\n",
      " -0.59699243 -0.59742135  0.07677678  0.07608116  0.07524445  0.07604122\n",
      " -0.59804565 -0.5970625  -0.5971885  -0.5970682   0.07575842  0.0757283\n",
      "  0.07729048  0.0777045  -0.26817244 -0.26770929 -0.2694624  -0.26960525\n",
      " -0.2701967  -0.26601642 -0.26502123 -0.2646969  -0.26624057 -0.26356813\n",
      " -0.59832495 -0.5980145  -0.5976998  -0.5977488   0.07533011  0.07344541\n",
      "  0.07291494  0.07245832  0.07547967  0.07681117  0.07837453  0.07797376\n",
      "  0.07356697  0.07221718  0.07223888  0.07327818  0.41164398  0.41072366\n",
      "  0.4100307   0.40839538 -0.59826726 -0.59742653 -0.5967887  -0.5956056\n",
      "  0.41073427  0.411976    0.41340137  0.41531637 -0.59772724 -0.5980664\n",
      " -0.59817845 -0.5978671  -0.2701039  -0.26999107 -0.26895934 -0.26910523\n",
      "  0.07005149  0.07306483  0.07384605  0.07171494  0.0685195  -0.59852904\n",
      " -0.5988248  -0.5966871  -0.598723    0.07670149  0.07904039  0.07836188\n",
      "  0.07816667  0.07615038  0.07499524  0.07145095  0.07188492  0.07511954\n",
      "  0.07558976  0.07967087  0.07933912  0.07889238  0.08044305  0.08014399\n",
      " -0.26534188 -0.26554313 -0.26581103 -0.26551312 -0.266205   -0.26682758\n",
      " -0.26526478 -0.26540262 -0.59553206 -0.5958324  -0.59586513 -0.59692067\n",
      " -0.26720446 -0.26756763 -0.2668175  -0.26626518  1.7283638   1.7151835\n",
      "  1.7209729   1.7278802   1.7181151  -0.59698087 -0.59517616 -0.5937193\n",
      " -0.59322816  1.4155563   1.406097    1.4255494   1.3949353   1.4108704\n",
      "  0.07518654  0.07580668  0.07636785  0.07467438 -0.26468956 -0.26719785\n",
      " -0.2677962  -0.26844975 -0.59834176 -0.5976998  -0.59796757 -0.59825975\n",
      " -0.597224   -0.5982547  -0.59841025 -0.59929734 -0.59788096 -0.5974822\n",
      " -0.59776825 -0.597762    0.07072689  0.070715    0.0689001   0.07065462\n",
      "  0.06994729 -0.24236055 -0.25778076 -0.26168564 -0.26081482 -0.25457358\n",
      " -0.59785825 -0.59925854 -0.5987098  -0.59739673 -0.2658253  -0.26539645\n",
      " -0.26552495 -0.26636377 -0.59725225 -0.5958173  -0.5965338  -0.59565914\n",
      " -0.2760775  -0.27517787 -0.27368405 -0.27645564 -0.27541435 -0.26680744\n",
      " -0.26887098 -0.26946113 -0.26955125 -0.26776716 -0.2674306  -0.2676804\n",
      " -0.26796407 -0.595819   -0.5960203  -0.59593695 -0.5977597   0.4156586\n",
      "  0.41698694  0.41632655  0.4150748  -0.59271216 -0.5917626  -0.59056234\n",
      " -0.58791435 -0.5861044  -0.26573718 -0.26438254 -0.2650887  -0.2646951\n",
      " -0.26675332 -0.26692998 -0.2663739  -0.26731414 -0.5944563  -0.5956718\n",
      " -0.59609836 -0.5968936  -0.5967734  -0.59665525 -0.5958014  -0.59756005\n",
      " -0.26868445 -0.2696669  -0.26856726 -0.26817808 -0.59769905 -0.59788215\n",
      " -0.598189   -0.59807116 -0.27173677 -0.27166042 -0.27082324 -0.27066743\n",
      " -0.2707706  -0.59892035 -0.5993385  -0.59644955 -0.5967241  -0.27020243\n",
      " -0.27359506 -0.27444088 -0.2767122  -0.27742395 -0.59700114 -0.5975069\n",
      " -0.595804   -0.59697455  0.07432596  0.07476746  0.07592978  0.07674263\n",
      " -0.5947734  -0.5964508  -0.5973172  -0.5976757  -0.26716608 -0.26685703\n",
      " -0.26686725 -0.26635042  0.4116774   0.41187534  0.41096708  0.41066915\n",
      "  0.07640453  0.07555614  0.07458258  0.0764209   0.07586656 -0.26844606\n",
      " -0.26817426 -0.2675166  -0.26689368 -0.26726362 -0.26698548 -0.2676087\n",
      " -0.26772022  0.07499132  0.07589787  0.07732855  0.0774157   0.08555979\n",
      "  0.08082429  0.08010348  0.0777562   0.07797641 -0.26912174 -0.26921374\n",
      " -0.2689154  -0.26888856 -0.59726506 -0.5968652  -0.59625083 -0.595743\n",
      " -0.596664   -0.59734136 -0.5982644  -0.5984263  -0.26812002 -0.2669538\n",
      " -0.26736426 -0.26795143  0.07548193  0.07464267  0.07414336  0.07453752\n",
      " -0.5973387  -0.5980762  -0.5971909  -0.59741974 -0.26744658 -0.26997802\n",
      " -0.26759553 -0.2673884  -0.26944482 -0.2659119  -0.26685864 -0.26740596\n",
      " -0.26696932  0.41589016  0.41561905  0.41533244  0.41526884 -0.26659176\n",
      " -0.2631779  -0.26548818 -0.26484725 -0.2639819  -0.26516423 -0.26651344\n",
      " -0.26715165 -0.26725    -0.26606756 -0.26676866 -0.2685038  -0.26946756\n",
      " -0.27058998]\n",
      "MSE for key X is: 1.1505159314551865\n",
      "MSE for key NIR is: 1.1721332861118563\n",
      "MSE for key IR is: 0.02752549342620067\n",
      "MSE for key Sub-mm is: 393.50502784653463\n",
      "Results saved to coverage_test.npz\n",
      "Figure(1000x800)\n"
     ]
    }
   ],
   "source": [
    "!python exe_real.py --modelfolder sgra_fold0_final_20250404_110307 --real_data_path ../Analysis/coverage_test_data.npz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion-Nf9kVZlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
